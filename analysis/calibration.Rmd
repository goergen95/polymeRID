---
title: "Calibration"
author: Darius Goergen
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: true
editor_options:
  chunk_output_type: console
bibliography: library.bib
csl: elsevier-harvard.csl
link-citations: yes
---

```{r calibration-setup, echo=FALSE, warning=FALSE, message=FALSE}
source("code/setup_website.R")
source("code/functions.R")
#data = read.csv(file = paste0(ref, "reference_database.csv"), header = TRUE)
```


## Overview

For the calibration a decision fusion between the best performing
models during the exploration stage was implemented. Since SVM-based models did not achieve very
high accuracies we only included two RF models and two CNNs. The RF models yielding 
to the highest accuracies were trained with the raw data and the Savitzkiy-Golay
smoothed data. For the CNNs we observed the highest accuracies with the 
second derivative of the raw data and with the second derivative of the normalized data. 
These models will be used during calibration. To gain an accuracy value
for the fusion approach, again a cross-validation will be used.

## Cross-Validation

The cross-validation of the decision fusion was conducted on ten folds and repeated
five times. The complete code can be found [here](https://github.com/goergen95/polymeRID/blob/master/code/FUSION.R).
For every fold, four models are trained and evaluated against a 50% test split.
The final class decision is then achieved by combining the probability output of each model
and assigning the class with the highest overall probability.

```{r calibration-decision-fusion, eval=FALSE}
    classRFRaw = as.character(predict(rfModRaw, pcaRaw_testing))
    propRFRaw =  predict(rfModRaw, pcaRaw_testing, type = "prob")
    classRFSG = as.character(predict(rfModSG, pcaSG_testing))
    propRFSG = predict(rfModSG, pcaSG_testing, type = "prob")
    classCNND2 = as.character(classes[keras::predict_classes(cnnD2, x_testD2)+1])
    propCNND2 = keras::predict_proba(cnnD2, x_testD2)
    classCNNND2 = as.character(classes[keras::predict_classes(cnnND2, x_testND2)+1])
    propCNNND2 = keras::predict_proba(cnnND2, x_testND2)

    # probability
    probs = (propRFRaw + propRFSG + propCNND2 + propCNNND2) / 4
    pred = lapply(1:nrow(probs), function(x){
      which.max(probs[x,])
    })

    predVals = lapply(1:nrow(probs), function(x){
      probs[x,unlist(pred)[x]]
    })


    predVals = unlist(predVals)
    pred= names(unlist(pred))
    obsv = as.character(testingRaw$class)

    pred[which(pred %in% c("FIBRE","FUR","WOOD"))] = "OTHER"
    obsv[which(obsv %in% c("FIBRE","FUR","WOOD"))] = "OTHER"

    obsv = as.factor(obsv)
    pred = as.factor(pred)
    cfMat = caret::confusionMatrix(pred,obsv)
```

Note, that the classes which are not synthetic polymers are combined to a class called
`OTHER` since we are only interested in the correct classification of plastic polymers.
When a particle is correctly identified as non-plastic the main goal of the analysis
is achieved, no matter if the different models disagree on the exact non-plastic class.
By using the `caret::confusionMatrix()` function overall accuracy values are easily extracted
as well as class specific metrics. 

## Results
```{r calibration-read-Results, echo=FALSE}
accuracies = readRDS(paste0(output, "fusion/meanAccuracyResults.rds"))
classInfo = readRDS(paste0(output, "fusion/meanClassResults.rds"))
```

By calculating the average across all folds and all repeats final accuracy results
are obtained.

```{r calibration-accuracy, echo=FALSE}
knitr::kable(round(accuracies[1:5],3), caption = "**Tab. 1**: Overall accuracy values for the decision fusion after cross-validation.",
             col.names = "value")

```

We achieved an overall accuracy of **91.4%** with a Kappa coefficient of 
0.89 (**Tab. 1**). This accuracy is substantially higher than compared to the single model
accuracies of RF and CNN. By the decision fusion and combining the non-synthetic 
classes we were able to rise the accuracy by about 5%.

```{r calibration-classInfo, echo=FALSE}
knitr::kable(round(classInfo,3), caption = "**Tab. 2**: Class-specific accuracy metrics for the decision fusion after cross-validation.")
```

Analyzing the class-specific accuracy metrics (**Tab. 2**) we observe that 
the lowest sensitivity is 0.69 for `PES`. That means that `PES` is most likely not to
be identified correctly. `PET` shows a similar low sensitivity value of 0.76.
`PP` shows the highest sensitivity value of 1, which means that all samples classified
as `PP` actually represent that class. Concerning the specificity, gor all classes
similar values of about 0.99 are observed. In general, it can stated that a very 
good distinction between non-synthetic polymers and microplastic polymers was achieved. 
However, some microplastic classes, such as `PES` and `PET` achieve only poor
accuracies (**0.84** and **0.86** of balanced accuracy respectively). These shortcomings
might be compensated for with extensions to the reference database. Machine learning 
algorithms can only learn from the database which is presented to them.
Therefore, adding reference samples could prove beneficial when it comes to accuracy.






