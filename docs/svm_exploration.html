<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Darius Goergen" />


<title>Support Vector Machine</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/spacelab.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="site_libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>
<link href="site_libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="site_libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="site_libs/plotly-main-1.46.1/plotly-latest.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">polymeRID</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="preparation.html">Preparation</a>
</li>
<li>
  <a href="exploration.html">Exploration</a>
</li>
<li>
  <a href="calibration.html">Calibration</a>
</li>
<li>
  <a href="classification.html">Classification</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Support Vector Machine</h1>
<h4 class="author">Darius Goergen</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2019-08-14
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 6 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong> <code>polymeRID/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.4.0.9001). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguncommittedchanges"> <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> <strong>R Markdown file:</strong> uncommitted changes </a>
</p>
</div>
<div id="strongRMarkdownfilestronguncommittedchanges" class="panel-collapse collapse">
<div class="panel-body">
<p>The R Markdown file has unstaged changes. To know which version of the R Markdown file created these results, you’ll want to first commit it to the Git repo. If you’re still working on the analysis, you can ignore this warning. When you’re finished, you can run <code>wflow_publish</code> to commit the R Markdown file and build the HTML.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20190729code"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Seed:</strong> <code>set.seed(20190729)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20190729code" class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20190729)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Session information:</strong> recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be confident that you successfully produced the results during this run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomgoergen95polymeRIDtree2385fbc4a358ad383e48ee613c51de466f49f1a2targetblank2385fbca"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/goergen95/polymeRID/tree/2385fbc4a358ad383e48ee613c51de466f49f1a2" target="_blank">2385fbc</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomgoergen95polymeRIDtree2385fbc4a358ad383e48ee613c51de466f49f1a2targetblank2385fbca" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rprofile
    Ignored:    .Rproj.user/
    Ignored:    analysis/library.bib
    Ignored:    docs/figure/
    Ignored:    fun/
    Ignored:    output/20190810_1538/
    Ignored:    output/20190810_1546/
    Ignored:    output/20190810_1609/
    Ignored:    output/20190813_1044/
    Ignored:    output/logs/
    Ignored:    output/natural/
    Ignored:    output/nnet/
    Ignored:    output/svm/
    Ignored:    output/testRunII/
    Ignored:    output/testRunIII/
    Ignored:    packrat/lib-R/
    Ignored:    packrat/lib-ext/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/BH/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/FactoMineR/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/IDPmisc/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/KernSmooth/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/MASS/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/Matrix/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/MatrixModels/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ModelMetrics/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/R6/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/RColorBrewer/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/Rcpp/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/RcppArmadillo/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/RcppEigen/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/RcppGSL/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/RcppZiggurat/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/Rfast/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/Rgtsvm/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/Rmisc/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/SQUAREM/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/SparseM/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/abind/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/askpass/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/assertthat/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/backports/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/base64enc/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/baseline/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/bit/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/bit64/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/boot/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/callr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/car/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/carData/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/caret/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/cellranger/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/class/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/cli/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/clipr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/cluster/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/codetools/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/colorspace/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/config/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/cowplot/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/crayon/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/crosstalk/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/curl/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/data.table/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/dendextend/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/digest/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/doParallel/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/dplyr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/e1071/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ellipse/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ellipsis/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/evaluate/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/factoextra/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/fansi/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/flashClust/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/forcats/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/foreach/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/foreign/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/fs/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/generics/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/getPass/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ggplot2/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ggpubr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ggrepel/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ggsci/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ggsignif/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/git2r/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/glue/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/gower/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/gridExtra/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/gtable/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/haven/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/hexbin/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/highr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/hms/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/htmltools/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/htmlwidgets/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/httpuv/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/httr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ipred/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/iterators/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/jsonlite/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/keras/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/kerasR/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/knitr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/labeling/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/later/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/lattice/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/lava/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/lazyeval/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/leaps/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/lme4/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/lubridate/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/magrittr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/maptools/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/markdown/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/mgcv/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/mime/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/minqa/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/munsell/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/nlme/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/nloptr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/nnet/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/numDeriv/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/openssl/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/openxlsx/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/packrat/tests/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/pbkrtest/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/pillar/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/pkgconfig/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/plogr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/plotly/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/plyr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/polynom/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/prettyunits/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/processx/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/prodlim/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/progress/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/promises/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/prospectr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ps/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/purrr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/quantreg/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/randomForest/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/readr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/readxl/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/recipes/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rematch/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/reshape2/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/reticulate/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rio/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rlang/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rmarkdown/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rpart/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rprojroot/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rstudioapi/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/scales/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/scatterplot3d/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/shiny/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/sourcetools/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/sp/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/stringi/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/stringr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/survival/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/sys/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tensorflow/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tfruns/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tibble/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tidyr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tidyselect/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/timeDate/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tinytex/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/utf8/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/vctrs/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/viridis/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/viridisLite/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/whisker/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/withr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/workflowr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/xfun/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/xtable/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/yaml/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/zeallot/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/zip/
    Ignored:    packrat/src/
    Ignored:    polymeRID.Rproj
    Ignored:    smp/20190812_1723_NNET/files/
    Ignored:    smp/20190812_1723_NNET/plots/
    Ignored:    smp/20190812_1729_NNET/files/
    Ignored:    smp/20190812_1729_NNET/plots/
    Ignored:    smp/20190812_1731_NNET/files/
    Ignored:    smp/20190812_1731_NNET/plots/
    Ignored:    smp/20190812_1733_NNET/files/
    Ignored:    smp/20190812_1733_NNET/plots/
    Ignored:    website/analysis/
    Ignored:    website/code/
    Ignored:    website/docs/
    Ignored:    website/mod/
    Ignored:    website/output/
    Ignored:    website/run/
    Ignored:    website/smp/

Unstaged changes:
    Modified:   analysis/rf_exploration.Rmd
    Modified:   analysis/svm_exploration.Rmd

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the R Markdown and HTML files. If you’ve configured a remote Git repository (see <code>?wflow_git_remote</code>), click on the hyperlinks in the table below to view them.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/goergen95/polymeRID/2385fbc4a358ad383e48ee613c51de466f49f1a2/docs/svm_exploration.html" target="_blank">2385fbc</a>
</td>
<td>
goergen95
</td>
<td>
2019-08-14
</td>
<td>
republish for layout change
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/goergen95/polymeRID/blob/293fd73b6f194574384917de64a3a16f695a6507/analysis/svm_exploration.Rmd" target="_blank">293fd73</a>
</td>
<td>
goergen95
</td>
<td>
2019-08-14
</td>
<td>
first step on svm_exploration
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/goergen95/polymeRID/293fd73b6f194574384917de64a3a16f695a6507/docs/svm_exploration.html" target="_blank">293fd73</a>
</td>
<td>
goergen95
</td>
<td>
2019-08-14
</td>
<td>
first step on svm_exploration
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<p>Support Vector Machine (SVM) is a non-parametric classification method which is initially designed for binary classification problems and which was developed in its current form by <span class="citation">Boser, Guyon, and Vapnik (<a href="#ref-Boser:1992:TAO:130385.130401">2004</a>)</span>. A detailed overview of the SVM algorithm is found in <span class="citation">Burges (<a href="#ref-Burges1998">1998</a>)</span>. The principal idea behind SVM is to find an optimal hyperplane which separates two classes from another by the largest possible margin. The alogrithm is optimised by iterativly maximizing this margin but while only considering the closest observations of both classes to the margin. These specific observations are also called support-vectors. Multidimensional data can be processed by mapping the data into a higher dimensional feature space through a specified mapping function. This function is called kernel function, and mainly four different groups are used: linear, polynomial, radial and sigmoid functions <span class="citation">(Burges <a href="#ref-Burges1998">1998</a>)</span>. In this project only the radial basis function was used. Multi-class problems are addressed by calculating an optimal margin following the one class-against-all pattern and conducting a majority vote and the end of the calculations. SVM need some tuning parameters. These are the regularization parameter <code>C</code> and the kernel width <code>γ</code>. The regularization parameter is also called penalty value, as it is a constant giving penalty to misclassified observations. There optimal values might change if different representations of the data are presented to the algorithm.</p>
<p>Different levels of data reprocessing might emphasize different features of the patterns to be learned by an algorithm. To grasp this, different transformations of the data were presented to the SVM algorithm. Additionally, the raw data signal was jittered to test which transformation might prove beneficial in delivering high classification accuracies even in the presence of noise. To test this, we define a function which adds noise to the raw data and returns a list with the number of elements equal to the levels of noise applied.</p>
<pre class="r"><code>addNoise = function(data, levels = c(0), category=&quot;class&quot;){
  data.return = list()
  index = which(names(data) == category)
  for (n in levels){
    tmp = as.matrix(data[ , -index])
    if (n == 0){
      tmp = data
    }else{
      tmp = as.data.frame(jitter(tmp, n))
      tmp[category] = data[category]
    }
    data.return[[paste(&quot;noise&quot;, n, sep=&quot;&quot;)]] = tmp
  }
  return(data.return)
}

data = read.csv(file = paste0(ref, &quot;reference_database.csv&quot;), header = TRUE)
noisy_data = addNoise(data, levels = c(0,10,100,250,500), category = &quot;class&quot;)

# indivitual elements can be selected by using [[ and refering to the index or the name
head(noisy_data[[&quot;noise100&quot;]])[1:3,1:3]</code></pre>
<pre><code>  wvn3992.63003826141 wvn3990.70123147964 wvn3988.77242469788
1        -0.010328834          0.01829306         0.001603137
2         0.005237827          0.01683373        -0.013921331
3        -0.011751581          0.01958805         0.002650597</code></pre>
<p>Then, in another user defined function which uses the <code>noisy_data</code> objected as input specified data transformations are applied. These are normalization which centers and scales the input data, as well as different forms of the Savitkiy-Golay filter <span class="citation">(Savitzky and Golay <a href="#ref-Savitzky1964">1964</a>)</span> and first and second derivative of a raw spectrum. The functions iterates through the noise level elements in the <code>noisy_data</code> object and returns each specified transformation in a list element below the noise level. The exemplary function below applies the preprocessing for normalization, standard filtering and first derivative only. The implementation of the function used in the project can be found <a href="https://github.com/goergen95/polymeRID/blob/master/code/functions.R#12">here</a>.</p>
<pre class="r"><code>createTrainingSet = function(data, category = &quot;class&quot;,
                             SGpara = list(p=3,w=11), lag = 15){
  
  data.return = list()
  for (noise in names(data)){
    
    tmp = as.data.frame(data[[noise]])
    classes = tmp[,category]
    tmp = tmp[!names(tmp) %in% category]
    
    # original data
    data.return[[noise]][[&quot;raw&quot;]] = as.data.frame(data[[noise]])
    
    # normalised data
    data_norm = preprocess(tmp, type=&quot;norm&quot;)
    data_norm[category] = classes
    data.return[[noise]][[&quot;norm&quot;]] = data_norm
    
    # SG-filtered data
    data_sg = preprocess(tmp, type=&quot;sg&quot;, SGpara = SGpara)
    data_sg[category] = classes
    data.return[[noise]][[&quot;sg&quot;]] = data_sg
    
    # first derivative of original data
    data_rawd1 = preprocess(tmp, type=&quot;raw.d1&quot;, lag = lag)
    data_rawd1[category] = classes
    data.return[[noise]][[&quot;raw.d1&quot;]] = data_rawd1
    
  }
  return(data.return)
}

# applying the function
test_dataset = createTrainingSet(noisy_data, category = &quot;class&quot;)

# individual transformations at a certain noise level can be accessed with [[
head(test_dataset[[&quot;noise500&quot;]][[&quot;raw.d1&quot;]])[1:3,1:3]</code></pre>
<pre><code>  wvn3963.69793653488 wvn3961.76912975311 wvn3959.84032297134
1          0.08295627          0.02234302          0.17399975
2          0.04253842          0.07918397          0.03849980
3         -0.05579848          0.11670539          0.02503375</code></pre>
<p>The data base of <span class="citation">(Primpke et al. <a href="#ref-Primpke2018">2018</a>)</span> currently shows 1863 variables for each observations. Most of these data points do not bear relevant information to distinguish between different types of particles. To shorten the computation time, one can use dimensionality reduction techniques such as principal component analysis (PCA). PCA also has been used to transform spectral data of micro-plastics in marine ecosystems before <span class="citation">(Jung et al. <a href="#ref-Jung2018">2018</a>; Lorenzo-Navarro et al. <a href="#ref-Lorenzo-Navarro2018">2018</a>)</span>. PCA basically takes the input data for a given number of observation and by performing a orthogonal transformation to the data transforms these possible correlated variables to uncorrelated principal components. This way, both redundancies in the data as well as possible noise can be accounted for. PCA previously has been successfully applied to FTIR-spectrometer data [<span class="citation">Hori and Sugiyama (<a href="#ref-Hori2003">2003</a>)</span>;<span class="citation">Nieuwoudt et al. (<a href="#ref-Nieuwoudt2004">2004</a>)</span>;<span class="citation">Mueller et al. (<a href="#ref-Mueller2013">2013</a>)</span>;<span class="citation">Ami, Mereghetti, and Maria (<a href="#ref-Ami2013">2013</a>)</span>;Fu2014]. Simultaniously, the number of variables can be significantly reduced by applying PCA and thus speeding up the training process. Below we will apply a PCA to the raw data as an example.</p>
<pre class="r"><code>library(factoextra)
tmp = test_dataset[[&quot;noise0&quot;]][[&quot;raw&quot;]]
pca = prcomp(tmp[ ,-1864]) # omitting class variable
var_info = factoextra::get_eigenvalue(pca)
# setting a threshold of 99% explained variance
threshold = 99
thresInd = which(var_info$cumulative.variance.percent&gt;=threshold)[1]
pca_data = pca$x[,1:thresInd]</code></pre>
<p>We can use the index variable <code>thresInd</code> we just defined to take a look upon all the principal components which explain 99% of the variance in the data set.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">eigenvalue</th>
<th align="right">variance.percent</th>
<th align="right">cumulative.variance.percent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Dim.1</td>
<td align="right">1.5618496</td>
<td align="right">57.7479523</td>
<td align="right">57.74795</td>
</tr>
<tr class="even">
<td>Dim.2</td>
<td align="right">0.3875503</td>
<td align="right">14.3293173</td>
<td align="right">72.07727</td>
</tr>
<tr class="odd">
<td>Dim.3</td>
<td align="right">0.2226548</td>
<td align="right">8.2324559</td>
<td align="right">80.30973</td>
</tr>
<tr class="even">
<td>Dim.4</td>
<td align="right">0.1823539</td>
<td align="right">6.7423696</td>
<td align="right">87.05209</td>
</tr>
<tr class="odd">
<td>Dim.5</td>
<td align="right">0.0897978</td>
<td align="right">3.3201919</td>
<td align="right">90.37229</td>
</tr>
<tr class="even">
<td>Dim.6</td>
<td align="right">0.0538395</td>
<td align="right">1.9906665</td>
<td align="right">92.36295</td>
</tr>
<tr class="odd">
<td>Dim.7</td>
<td align="right">0.0443676</td>
<td align="right">1.6404525</td>
<td align="right">94.00341</td>
</tr>
<tr class="even">
<td>Dim.8</td>
<td align="right">0.0324243</td>
<td align="right">1.1988595</td>
<td align="right">95.20227</td>
</tr>
<tr class="odd">
<td>Dim.9</td>
<td align="right">0.0297937</td>
<td align="right">1.1015939</td>
<td align="right">96.30386</td>
</tr>
<tr class="even">
<td>Dim.10</td>
<td align="right">0.0215566</td>
<td align="right">0.7970366</td>
<td align="right">97.10090</td>
</tr>
<tr class="odd">
<td>Dim.11</td>
<td align="right">0.0173647</td>
<td align="right">0.6420450</td>
<td align="right">97.74294</td>
</tr>
<tr class="even">
<td>Dim.12</td>
<td align="right">0.0145994</td>
<td align="right">0.5397977</td>
<td align="right">98.28274</td>
</tr>
<tr class="odd">
<td>Dim.13</td>
<td align="right">0.0113917</td>
<td align="right">0.4211964</td>
<td align="right">98.70394</td>
</tr>
<tr class="even">
<td>Dim.14</td>
<td align="right">0.0069264</td>
<td align="right">0.2560972</td>
<td align="right">98.96003</td>
</tr>
<tr class="odd">
<td>Dim.15</td>
<td align="right">0.0042735</td>
<td align="right">0.1580104</td>
<td align="right">99.11804</td>
</tr>
</tbody>
</table>
<p>We effectivly reduced the number of variables from 1683 to 15 which still bear 99% of the variance we can find in the original data set. However, when it comes to machine learning, it is important to realise that this new dataset is not fit to be used in a training process. If we now randomly split the observations into training and test, we effectivly mix up these two sets because information of the test set has already influenced the outcome of the PCA. Therefor, the data set need to be split beforhand of the PCA. The analysis is done on the training data only and then the same orthogonal transformations will be applied to the test data. This way it can be ensured that the test set is truely independent from the training process. Here, we apply a 10-fold cross-validation which is repeated 5 times. The following code takes a complete data set as input, applies a splitting function from the <code>caret</code> package and then builds the PCA upon the the test set and finally applies the same transformation to the test set. We apply it for the raw data only. Also, we randomly split the data to 50% training and 50% test.</p>
<pre class="r"><code>folds = 10
repeats = 5
split_percentage = 0.5
threshold = 99
tmp = test_dataset[[&quot;noise0&quot;]][[&quot;raw&quot;]]

set.seed(42) # ensure reproducibility
fold_index = lapply(1:repeats, caret::createDataPartition, y=tmp$class,
                   times = folds, p = split_percentage)
fold_index = do.call(c, fold_index)

pcaData = list()
for (rep in 1:repeats){
  rep_index = fold_index[(rep*folds-folds+1):(rep*folds)] # jumps to the correct number of folds forward in each repeat
  
  pcadata_fold = lapply(1:folds,function(x){
    
    # splitting for current fold
    training = tmp[unlist(rep_index[x]),]
    validation = tmp[-unlist(rep_index[x]),]
    
    # keep response
    responseTrain = training$class
    responseVal = validation$class
    
    # apply PCA
    pca = prcomp(training[,1:1863])
    varInfo = factoextra::get_eigenvalue(pca)
    thresInd = which(varInfo$cumulative.variance.percent &gt;= threshold)[1]
    pca_training = pca$x[ ,1:thresInd]
    pca_validation = predict(pca, validation)[ ,1:thresInd]
    
    training = as.data.frame(pca_training)
    training$response = responseTrain
    validation = as.data.frame(pca_validation)
    validation$response = responseVal
    foldtmp = list(training, validation)
    names(foldtmp) = c(&quot;training&quot;,&quot;validation&quot;)
    return(foldtmp)
  })
  names(pcadata_fold) = paste(&quot;fold&quot;, 1:folds, sep =&quot;&quot;)
  pcaData[[paste0(&quot;repeat&quot;,rep)]] = pcadata_fold
}</code></pre>
<p>We now have a list object with the number of elements equivalent to the repeats. Below each repeat element we can access the individual folds. There we find two elements which we can access by refering to <code>&quot;training&quot;</code> and <code>&quot;testing&quot;</code>.</p>
<pre class="r"><code>pcaData[[&quot;repeat5&quot;]][[&quot;fold10&quot;]][[&quot;training&quot;]][1:3,1:3]</code></pre>
<pre><code>         PC1        PC2         PC3
1 -0.4779164 -0.7786770 -0.02761266
2 -0.4869471 -0.7181236 -0.02492981
4 -0.4661699 -0.7463479 -0.11424932</code></pre>
<pre class="r"><code>pcaData[[&quot;repeat5&quot;]][[&quot;fold10&quot;]][[&quot;validation&quot;]][1:3,1:3]</code></pre>
<pre><code>         PC1        PC2         PC3
3 -0.5240744 -0.5931111  0.05961383
5 -0.4718366 -0.6995376 -0.09273887
7 -0.5255215 -0.5928214  0.05184969</code></pre>
<pre class="r"><code>summary(pcaData[[&quot;repeat5&quot;]][[&quot;fold10&quot;]][[&quot;training&quot;]]$response)</code></pre>
<pre><code>FIBRE   FUR  HDPE  LDPE    PA    PE   PES   PET    PP    PS   PUR  WOOD 
   14    12     5     6     7     4     8     5     6     4     4     2 </code></pre>
<pre class="r"><code>summary(pcaData[[&quot;repeat5&quot;]][[&quot;fold10&quot;]][[&quot;validation&quot;]]$response)</code></pre>
<pre><code>FIBRE   FUR  HDPE  LDPE    PA    PE   PES   PET    PP    PS   PUR  WOOD 
   13    11     5     5     7     4     7     4     6     3     3     2 </code></pre>
<p>For the SVM algorithm we also implementd a simple search pattern for optimal paramters for the regularization parameter <code>C</code> and the kernel width <code>γ</code>. We did this by applying a search grid for the paramters and calculating each possible combination. Note that due to limits in computation capacities we restriced the search to 25 combinations only. The code below calculates a model for each possible combinations, evaluating it capacity to correctly classify the training data and then chooses the optimal model to evaluate the validation data.</p>
<pre class="r"><code>training = pcaData[[&quot;repeat1&quot;]][[&quot;fold1&quot;]][[&quot;training&quot;]]
validation =pcaData[[&quot;repeat1&quot;]][[&quot;fold1&quot;]][[&quot;validation&quot;]]
x_train = training[ ,1:ncol(training)-1]
y_train = training$response
x_test = validation[ ,1:ncol(validation)-1]
y_test = validation$response


tuneGrid = expand.grid(gamma =seq(0.1,1,0.2),cost = seq(1,5,1) )
accuracy = c()
models = list()
for ( i in 1:nrow(tuneGrid)){
  model = e1071::svm(x = x_train, y = y_train,
                    kernel = &quot;radial&quot;,
                    gamma = tuneGrid$gamma[i],
                    cost = tuneGrid$cost[i])
  pred = predict(model, x_train)
  conf = caret::confusionMatrix(pred, y_train)
  accuracy = c(accuracy, conf$overall[&quot;Kappa&quot;])
  models[[i]] = model
}

best_model = models[[which(accuracy == max(accuracy))[1]]]
prediction = predict(best_model, x_test)
confMat = caret::confusionMatrix(prediction, y_test)
print(confMat$table)</code></pre>
<pre><code>          Reference
Prediction FIBRE FUR HDPE LDPE PA PE PES PET PP PS PUR WOOD
     FIBRE    12   0    0    0  0  0   5   2  0  0   0    2
     FUR       1  11    0    0  0  0   0   0  0  0   0    0
     HDPE      0   0    3    0  0  0   0   0  0  0   0    0
     LDPE      0   0    0    5  0  2   0   0  0  0   0    0
     PA        0   0    0    0  7  0   0   0  0  0   0    0
     PE        0   0    1    0  0  2   0   0  0  0   0    0
     PES       0   0    0    0  0  0   2   1  0  0   0    0
     PET       0   0    1    0  0  0   0   1  0  2   0    0
     PP        0   0    0    0  0  0   0   0  6  0   0    0
     PS        0   0    0    0  0  0   0   0  0  1   0    0
     PUR       0   0    0    0  0  0   0   0  0  0   3    0
     WOOD      0   0    0    0  0  0   0   0  0  0   0    0</code></pre>
<p>This code is integrated into a function which applies this search pattern to all folds for all repeats and can be found <a href="https://github.com/goergen95/polymeRID/blob/master/code/functions.R#321">here</a>. Finally, we can apply this function to the different levels of preprocssing which were discussed before and obtaining the accuracies in the <code>results</code> object.</p>
<pre class="r"><code>source(&quot;code/functions.R&quot;)
wavenumbers = readRDS(paste0(ref,&quot;wavenumbers.rds&quot;))
# add noise to data
noisyData = addNoise(data,levels = c(0,10,100,250,500), category = &quot;class&quot;)

# preprocessing
testDataset = createTrainingSet(noisyData, category = &quot;class&quot;,
                                SGpara = list(p=3, w=11), lag=15,
                                type = c(&quot;raw&quot;, &quot;norm&quot;, &quot;sg&quot;, &quot;sg.d1&quot;, &quot;sg.d2&quot;,
                                  &quot;sg.norm&quot;, &quot;sg.norm.d1&quot;, &quot;sg.norm.d2&quot;,
                                  &quot;raw.d1&quot;, &quot;raw.d2&quot;, &quot;norm.d1&quot;, &quot;norm.d2&quot;))


types = names(testDataset[[1]])

levels = lapply(names(testDataset), function(x){
  rep(x, length(types))
})
levels = unlist(levels)

results = data.frame(level=levels, type = types, kappa = rep(0,length(levels)))

for (level in unique(levels)){
  for (type in types){

    print(paste0(&quot;Level: &quot;,level,&quot; Type: &quot;,type))
    tmpData = testDataset[[level]][[type]]
    tmpData[which(wavenumbers&lt;=2420 &amp; wavenumbers&gt;=2200)] = 0 # setting C02 window to 0
    tmpModel = pcaCV(tmpData, folds = 10, repeats = 5, threshold = 99, metric = &quot;Kappa&quot;, p=0.5, method=&quot;svm&quot;)
    saveRDS(tmpModel,file = paste0(output,&quot;svm/model_&quot;,level,&quot;_&quot;,type,&quot;_&quot;,round(tmpModel[[1]],2),&quot;.rds&quot;))
    results[which(results$level==level &amp; results$type==type),&quot;kappa&quot;] = as.numeric(tmpModel[[1]])
    print(results)

  }
}
saveRDS(results, paste0(output,&quot;svm/exploration.rds&quot;))</code></pre>
<p>We can now take a look at the kappa scores the algorithm achived during training for different representations of the data and at increasing noise levels.</p>
<p><div id="htmlwidget-851b824557736d249baa" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-851b824557736d249baa">{"x":{"data":[{"x":[1,2,3,4,5],"y":[0.585334232290825,0,0,0,0],"text":["level: noise0<br />kappa: 0.585334232<br />type: norm<br />type: norm","level: noise10<br />kappa: 0.000000000<br />type: norm<br />type: norm","level: noise100<br />kappa: 0.000000000<br />type: norm<br />type: norm","level: noise250<br />kappa: 0.000000000<br />type: norm<br />type: norm","level: noise500<br />kappa: 0.000000000<br />type: norm<br />type: norm"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(248,118,109,1)","dash":"solid"},"hoveron":"points","name":"norm","legendgroup":"norm","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5],"y":[0.75539707068481,0.754283124026675,0,0,0],"text":["level: noise0<br />kappa: 0.755397071<br />type: raw<br />type: raw","level: noise10<br />kappa: 0.754283124<br />type: raw<br />type: raw","level: noise100<br />kappa: 0.000000000<br />type: raw<br />type: raw","level: noise250<br />kappa: 0.000000000<br />type: raw<br />type: raw","level: noise500<br />kappa: 0.000000000<br />type: raw<br />type: raw"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(216,144,0,1)","dash":"solid"},"hoveron":"points","name":"raw","legendgroup":"raw","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5],"y":[0.720276152878721,0.703512371623671,0,0,0],"text":["level: noise0<br />kappa: 0.720276153<br />type: raw.d1<br />type: raw.d1","level: noise10<br />kappa: 0.703512372<br />type: raw.d1<br />type: raw.d1","level: noise100<br />kappa: 0.000000000<br />type: raw.d1<br />type: raw.d1","level: noise250<br />kappa: 0.000000000<br />type: raw.d1<br />type: raw.d1","level: noise500<br />kappa: 0.000000000<br />type: raw.d1<br />type: raw.d1"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(163,165,0,1)","dash":"solid"},"hoveron":"points","name":"raw.d1","legendgroup":"raw.d1","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5],"y":[0.71717842736148,0.700979516042116,0,0,0],"text":["level: noise0<br />kappa: 0.717178427<br />type: raw.d2<br />type: raw.d2","level: noise10<br />kappa: 0.700979516<br />type: raw.d2<br />type: raw.d2","level: noise100<br />kappa: 0.000000000<br />type: raw.d2<br />type: raw.d2","level: noise250<br />kappa: 0.000000000<br />type: raw.d2<br />type: raw.d2","level: noise500<br />kappa: 0.000000000<br />type: raw.d2<br />type: raw.d2"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(57,182,0,1)","dash":"solid"},"hoveron":"points","name":"raw.d2","legendgroup":"raw.d2","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5],"y":[0.760137446451031,0.759410260860537,0.554081220659393,0,0],"text":["level: noise0<br />kappa: 0.760137446<br />type: sg<br />type: sg","level: noise10<br />kappa: 0.759410261<br />type: sg<br />type: sg","level: noise100<br />kappa: 0.554081221<br />type: sg<br />type: sg","level: noise250<br />kappa: 0.000000000<br />type: sg<br />type: sg","level: noise500<br />kappa: 0.000000000<br />type: sg<br />type: sg"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(0,191,125,1)","dash":"solid"},"hoveron":"points","name":"sg","legendgroup":"sg","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5],"y":[0.649352987220646,0.634460951213851,0,0,0],"text":["level: noise0<br />kappa: 0.649352987<br />type: sg.d1<br />type: sg.d1","level: noise10<br />kappa: 0.634460951<br />type: sg.d1<br />type: sg.d1","level: noise100<br />kappa: 0.000000000<br />type: sg.d1<br />type: sg.d1","level: noise250<br />kappa: 0.000000000<br />type: sg.d1<br />type: sg.d1","level: noise500<br />kappa: 0.000000000<br />type: sg.d1<br />type: sg.d1"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(0,191,196,1)","dash":"solid"},"hoveron":"points","name":"sg.d1","legendgroup":"sg.d1","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5],"y":[0.649049452484012,0.584830312210792,0,0,0],"text":["level: noise0<br />kappa: 0.649049452<br />type: sg.d2<br />type: sg.d2","level: noise10<br />kappa: 0.584830312<br />type: sg.d2<br />type: sg.d2","level: noise100<br />kappa: 0.000000000<br />type: sg.d2<br />type: sg.d2","level: noise250<br />kappa: 0.000000000<br />type: sg.d2<br />type: sg.d2","level: noise500<br />kappa: 0.000000000<br />type: sg.d2<br />type: sg.d2"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(0,176,246,1)","dash":"solid"},"hoveron":"points","name":"sg.d2","legendgroup":"sg.d2","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5],"y":[0.604578639734858,0.00396649136082936,0,0,0],"text":["level: noise0<br />kappa: 0.604578640<br />type: sg.norm<br />type: sg.norm","level: noise10<br />kappa: 0.003966491<br />type: sg.norm<br />type: sg.norm","level: noise100<br />kappa: 0.000000000<br />type: sg.norm<br />type: sg.norm","level: noise250<br />kappa: 0.000000000<br />type: sg.norm<br />type: sg.norm","level: noise500<br />kappa: 0.000000000<br />type: sg.norm<br />type: sg.norm"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(149,144,255,1)","dash":"solid"},"hoveron":"points","name":"sg.norm","legendgroup":"sg.norm","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5],"y":[0.230005728445566,0,0,0,0],"text":["level: noise0<br />kappa: 0.230005728<br />type: sg.norm.d1<br />type: sg.norm.d1","level: noise10<br />kappa: 0.000000000<br />type: sg.norm.d1<br />type: sg.norm.d1","level: noise100<br />kappa: 0.000000000<br />type: sg.norm.d1<br />type: sg.norm.d1","level: noise250<br />kappa: 0.000000000<br />type: sg.norm.d1<br />type: sg.norm.d1","level: noise500<br />kappa: 0.000000000<br />type: sg.norm.d1<br />type: sg.norm.d1"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(231,107,243,1)","dash":"solid"},"hoveron":"points","name":"sg.norm.d1","legendgroup":"sg.norm.d1","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5],"y":[0.23240906511033,0,0,0,0],"text":["level: noise0<br />kappa: 0.232409065<br />type: sg.norm.d2<br />type: sg.norm.d2","level: noise10<br />kappa: 0.000000000<br />type: sg.norm.d2<br />type: sg.norm.d2","level: noise100<br />kappa: 0.000000000<br />type: sg.norm.d2<br />type: sg.norm.d2","level: noise250<br />kappa: 0.000000000<br />type: sg.norm.d2<br />type: sg.norm.d2","level: noise500<br />kappa: 0.000000000<br />type: sg.norm.d2<br />type: sg.norm.d2"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(255,98,188,1)","dash":"solid"},"hoveron":"points","name":"sg.norm.d2","legendgroup":"sg.norm.d2","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":26.2283105022831,"r":7.30593607305936,"b":40.1826484018265,"l":43.1050228310502},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.4,5.6],"tickmode":"array","ticktext":["noise0","noise10","noise100","noise250","noise500"],"tickvals":[1,2,3,4,5],"categoryorder":"array","categoryarray":["noise0","noise10","noise100","noise250","noise500"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":{"text":"Noise level","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.0380068723225516,0.798144318773583],"tickmode":"array","ticktext":["0.0","0.2","0.4","0.6"],"tickvals":[0,0.2,0.4,0.6],"categoryorder":"array","categoryarray":["0.0","0.2","0.4","0.6"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":{"text":"Kappa score","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":true,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895},"y":0.96751968503937},"annotations":[{"text":"Type of<br />Pre-Processing","x":1.02,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"left","yanchor":"bottom","legendTitle":true}],"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","showSendToCloud":false},"source":"A","attrs":{"33e01d4f27f2":{"x":{},"y":{},"colour":{},"type":"scatter"}},"cur_data":"33e01d4f27f2","visdat":{"33e01d4f27f2":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script> We can observe that with higher noise ratios the kappa score is reduced significantly. All data transformations yield to very low accuracies when the noise is increases. In the absence of significant noise, however, the simple Savitzkiy-Golay filter, the raw data as well as the first and second order derivatives yield to a kappa score of about 0.75. We can look at this more mathmatically by calculating the average slopes of the data tranformations methods and order the data frame from low to high slopes. Note that we only take the kappa score at noise level 0 and 10 to calculate the average slope.</p>
<pre class="r"><code>noise0 = results[results$level == &quot;noise0&quot;, ]
noise10 = results[results$level == &quot;noise10&quot;, ]
slopes = noise10$kappa - noise0$kappa 
types = unique(results$type)
df = data.frame(type = types, slope = slopes, row.names = NULL)
df = df[order(-slopes),]</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">type</th>
<th align="right">slope</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>3</td>
<td align="left">sg</td>
<td align="right">-0.0007272</td>
</tr>
<tr class="even">
<td>1</td>
<td align="left">raw</td>
<td align="right">-0.0011139</td>
</tr>
<tr class="odd">
<td>4</td>
<td align="left">sg.d1</td>
<td align="right">-0.0148920</td>
</tr>
<tr class="even">
<td>10</td>
<td align="left">raw.d2</td>
<td align="right">-0.0161989</td>
</tr>
<tr class="odd">
<td>9</td>
<td align="left">raw.d1</td>
<td align="right">-0.0167638</td>
</tr>
<tr class="even">
<td>5</td>
<td align="left">sg.d2</td>
<td align="right">-0.0642191</td>
</tr>
<tr class="odd">
<td>7</td>
<td align="left">sg.norm.d1</td>
<td align="right">-0.2300057</td>
</tr>
<tr class="even">
<td>8</td>
<td align="left">sg.norm.d2</td>
<td align="right">-0.2324091</td>
</tr>
<tr class="odd">
<td>2</td>
<td align="left">norm</td>
<td align="right">-0.5853342</td>
</tr>
<tr class="even">
<td>6</td>
<td align="left">sg.norm</td>
<td align="right">-0.6006121</td>
</tr>
</tbody>
</table>
<p>We can now confirm, that the average decrease in kappa score is the lowest for the Savitzkiy-Golay filtered data followed by the raw data. Then, the first derivative of the filtered data achieves the next lowest slope, but it has to be noted that the overall kappa score level of this data transformation is lower than for the derivatives of the unfiltered data.</p>
<div id="citations-on-this-page" class="section level2">
<h2>Citations on this page</h2>
<div id="refs">
<div id="ref-Ami2013">
<p>Ami, Diletta, Paolo Mereghetti, and Silvia Maria. 2013. “Multivariate Analysis for Fourier Transform Infrared Spectra of Complex Biological Systems and Processes.” <em>Multivariate Analysis in Management, Engineering and the Sciences</em>. <a href="https://doi.org/10.5772/53850">https://doi.org/10.5772/53850</a>.</p>
</div>
<div id="ref-Boser:1992:TAO:130385.130401">
<p>Boser, Bernhard E., Isabelle M. Guyon, and Vladimir N. Vapnik. 2004. “A training algorithm for optimal margin classifiers.” In <em>Proceedings of the Fifth Annual Workshop on Computational Learning Theory</em>, 144–52. COLT ’92. New York, NY, USA: ACM. <a href="https://doi.org/10.1145/130385.130401">https://doi.org/10.1145/130385.130401</a>.</p>
</div>
<div id="ref-Burges1998">
<p>Burges, Christopher J.C. 1998. “A tutorial on support vector machines for pattern recognition.” <em>Data Mining and Knowledge Discovery</em> 2 (2): 121–67. <a href="https://doi.org/10.1023/A:1009715923555">https://doi.org/10.1023/A:1009715923555</a>.</p>
</div>
<div id="ref-Hori2003">
<p>Hori, Ritsuko, and Junji Sugiyama. 2003. “A combined FT-IR microscopy and principal component analysis on softwood cell walls.” <em>Carbohydrate Polymers</em> 52 (4): 449–53. <a href="https://doi.org/10.1016/S0144-8617(03)00013-4">https://doi.org/10.1016/S0144-8617(03)00013-4</a>.</p>
</div>
<div id="ref-Jung2018">
<p>Jung, Melissa R., F. David Horgen, Sara V. Orski, Viviana Rodriguez C., Kathryn L. Beers, George H. Balazs, T. Todd Jones, et al. 2018. “Validation of ATR FT-IR to identify polymers of plastic marine debris, including those ingested by marine organisms.” <em>Marine Pollution Bulletin</em> 127 (December 2017). Elsevier: 704–16. <a href="https://doi.org/10.1016/j.marpolbul.2017.12.061">https://doi.org/10.1016/j.marpolbul.2017.12.061</a>.</p>
</div>
<div id="ref-Lorenzo-Navarro2018">
<p>Lorenzo-Navarro, Javier, Modesto Castrillón-Santana, May Gómez, Alicia Herrera, and Pedro A Marín-Reyes. 2018. “Automatic Counting and Classification of Microplastic Particles.” <a href="https://doi.org/10.5220/0006725006460652">https://doi.org/10.5220/0006725006460652</a>.</p>
</div>
<div id="ref-Mueller2013">
<p>Mueller, Daniela, Marco Flôres Ferrão, Luciano Marder, Adilson Ben da Costa, and Rosana de Cássia de Souza Schneider. 2013. “Fourier transform infrared spectroscopy (FTIR) and multivariate analysis for identification of different vegetable oils used in biodiesel production.” <em>Sensors (Switzerland)</em> 13 (4): 4258–71. <a href="https://doi.org/10.3390/s130404258">https://doi.org/10.3390/s130404258</a>.</p>
</div>
<div id="ref-Nieuwoudt2004">
<p>Nieuwoudt, Helene H., Bernard A. Prior, Isak S. Pretorius, Marena Manley, and Florian F. Bauer. 2004. “Principal component analysis applied to Fourier transform infrared spectroscopy for the design of calibration sets for glycerol prediction models in wine and for the detection and classification of outlier samples.” <em>Journal of Agricultural and Food Chemistry</em> 52 (12): 3726–35. <a href="https://doi.org/10.1021/jf035431q">https://doi.org/10.1021/jf035431q</a>.</p>
</div>
<div id="ref-Primpke2018">
<p>Primpke, Sebastian, Marisa Wirth, Claudia Lorenz, and Gunnar Gerdts. 2018. “Reference database design for the automated analysis of microplastic samples based on Fourier transform infrared (FTIR) spectroscopy.” <em>Analytical and Bioanalytical Chemistry</em> 410 (21). Analytical; Bioanalytical Chemistry: 5131–41. <a href="https://doi.org/10.1007/s00216-018-1156-x">https://doi.org/10.1007/s00216-018-1156-x</a>.</p>
</div>
<div id="ref-Savitzky1964">
<p>Savitzky, Abraham, and Marcel J.E. Golay. 1964. “Smoothing and Differentiation of Data by Simplified Least Squares Procedures.” <em>Analytical Chemistry</em> 36 (8): 1627–39. <a href="https://doi.org/10.1021/ac60214a047">https://doi.org/10.1021/ac60214a047</a>.</p>
</div>
</div>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span> Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.6.1 (2019-07-05)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Linux Mint 19.1

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] plotly_4.9.0              knitr_1.24               
 [3] factoextra_1.0.5          tensorflow_1.14.0        
 [5] abind_1.4-5               e1071_1.7-2              
 [7] keras_2.2.4.1             workflowr_1.4.0.9001     
 [9] baseline_1.2-1            gridExtra_2.3            
[11] stringr_1.4.0             prospectr_0.1.3          
[13] RcppArmadillo_0.9.600.4.0 openxlsx_4.1.0.1         
[15] magrittr_1.5              ggplot2_3.2.0            
[17] reshape2_1.4.3            dplyr_0.8.3              

loaded via a namespace (and not attached):
 [1] httr_1.4.1         tidyr_0.8.3        viridisLite_0.3.0 
 [4] jsonlite_1.6       splines_3.6.1      foreach_1.4.7     
 [7] prodlim_2018.04.18 shiny_1.3.2        assertthat_0.2.1  
[10] stats4_3.6.1       highr_0.8          yaml_2.2.0        
[13] ggrepel_0.8.1      ipred_0.9-9        pillar_1.4.2      
[16] backports_1.1.4    lattice_0.20-38    glue_1.3.1        
[19] reticulate_1.13    digest_0.6.20      promises_1.0.1    
[22] colorspace_1.4-1   recipes_0.1.6      httpuv_1.5.1      
[25] htmltools_0.3.6    Matrix_1.2-17      plyr_1.8.4        
[28] timeDate_3043.102  pkgconfig_2.0.2    SparseM_1.77      
[31] caret_6.0-84       xtable_1.8-4       purrr_0.3.2       
[34] scales_1.0.0       whisker_0.3-2      later_0.8.0       
[37] gower_0.2.1        lava_1.6.5         git2r_0.26.1      
[40] tibble_2.1.3       generics_0.0.2     withr_2.1.2       
[43] nnet_7.3-12        lazyeval_0.2.2     mime_0.7          
[46] survival_2.44-1.1  crayon_1.3.4       evaluate_0.14     
[49] fs_1.3.1           nlme_3.1-140       MASS_7.3-51.4     
[52] class_7.3-15       tools_3.6.1        data.table_1.12.2 
[55] munsell_0.5.0      zip_2.0.3          compiler_3.6.1    
[58] rlang_0.4.0        grid_3.6.1         iterators_1.0.12  
[61] htmlwidgets_1.3    crosstalk_1.0.0    labeling_0.3      
[64] base64enc_0.1-3    rmarkdown_1.14     gtable_0.3.0      
[67] ModelMetrics_1.2.2 codetools_0.2-16   R6_2.4.0          
[70] tfruns_1.4         lubridate_1.7.4    zeallot_0.1.0     
[73] rprojroot_1.3-2    stringi_1.4.3      Rcpp_1.0.2        
[76] rpart_4.1-15       tidyselect_0.2.5   xfun_0.8          </code></pre>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
