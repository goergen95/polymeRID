<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Darius Goergen" />


<title>Convolutional Neural Network</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/spacelab.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="site_libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>
<link href="site_libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="site_libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="site_libs/plotly-main-1.46.1/plotly-latest.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">polymeRID</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="preparation.html">Preparation</a>
</li>
<li>
  <a href="exploration.html">Exploration</a>
</li>
<li>
  <a href="calibration.html">Calibration</a>
</li>
<li>
  <a href="classification.html">Classification</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Convolutional Neural Network</h1>
<h4 class="author">Darius Goergen</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2019-08-15
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 6 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong> <code>polymeRID/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.4.0.9001). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguncommittedchanges"> <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> <strong>R Markdown file:</strong> uncommitted changes </a>
</p>
</div>
<div id="strongRMarkdownfilestronguncommittedchanges" class="panel-collapse collapse">
<div class="panel-body">
<p>The R Markdown is untracked by Git. To know which version of the R Markdown file created these results, you’ll want to first commit it to the Git repo. If you’re still working on the analysis, you can ignore this warning. When you’re finished, you can run <code>wflow_publish</code> to commit the R Markdown file and build the HTML.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20190729code"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Seed:</strong> <code>set.seed(20190729)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20190729code" class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20190729)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Session information:</strong> recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be confident that you successfully produced the results during this run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomgoergen95polymeRIDtree6bef5e610a810c0749645c671bffe431f5236718targetblank6bef5e6a"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/goergen95/polymeRID/tree/6bef5e610a810c0749645c671bffe431f5236718" target="_blank">6bef5e6</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomgoergen95polymeRIDtree6bef5e610a810c0749645c671bffe431f5236718targetblank6bef5e6a" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rprofile
    Ignored:    .Rproj.user/
    Ignored:    analysis/library.bib
    Ignored:    fun/
    Ignored:    output/20190810_1538/
    Ignored:    output/20190810_1546/
    Ignored:    output/20190810_1609/
    Ignored:    output/20190813_1044/
    Ignored:    output/logs/
    Ignored:    output/natural/
    Ignored:    output/nnet/
    Ignored:    output/svm/
    Ignored:    output/testRunII/
    Ignored:    output/testRunIII/
    Ignored:    packrat/lib-R/
    Ignored:    packrat/lib-ext/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/BH/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/FactoMineR/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/IDPmisc/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/KernSmooth/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/MASS/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/Matrix/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/MatrixModels/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ModelMetrics/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/R6/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/RColorBrewer/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/Rcpp/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/RcppArmadillo/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/RcppEigen/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/RcppGSL/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/RcppZiggurat/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/Rfast/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/Rgtsvm/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/Rmisc/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/SQUAREM/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/SparseM/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/abind/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/askpass/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/assertthat/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/backports/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/base64enc/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/baseline/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/bit/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/bit64/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/boot/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/callr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/car/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/carData/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/caret/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/cellranger/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/class/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/cli/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/clipr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/cluster/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/codetools/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/colorspace/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/config/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/cowplot/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/crayon/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/crosstalk/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/curl/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/data.table/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/dendextend/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/digest/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/doParallel/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/dplyr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/e1071/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ellipse/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ellipsis/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/evaluate/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/factoextra/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/fansi/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/flashClust/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/forcats/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/foreach/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/foreign/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/fs/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/generics/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/getPass/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ggplot2/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ggpubr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ggrepel/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ggsci/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ggsignif/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/git2r/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/glue/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/gower/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/gridExtra/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/gtable/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/haven/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/hexbin/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/highr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/hms/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/htmltools/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/htmlwidgets/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/httpuv/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/httr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ipred/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/iterators/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/jsonlite/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/keras/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/kerasR/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/knitr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/labeling/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/later/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/lattice/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/lava/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/lazyeval/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/leaps/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/lme4/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/lubridate/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/magrittr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/maptools/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/markdown/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/mgcv/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/mime/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/minqa/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/munsell/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/nlme/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/nloptr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/nnet/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/numDeriv/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/openssl/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/openxlsx/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/packrat/tests/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/pbkrtest/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/pillar/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/pkgconfig/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/plogr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/plotly/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/plyr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/polynom/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/prettyunits/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/processx/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/prodlim/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/progress/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/promises/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/prospectr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/ps/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/purrr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/quantreg/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/randomForest/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/readr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/readxl/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/recipes/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rematch/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/reshape2/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/reticulate/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rio/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rlang/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rmarkdown/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rpart/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rprojroot/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/rstudioapi/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/scales/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/scatterplot3d/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/shiny/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/sourcetools/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/sp/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/stringi/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/stringr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/survival/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/sys/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tensorflow/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tfruns/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tibble/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tidyr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tidyselect/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/timeDate/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/tinytex/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/utf8/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/vctrs/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/viridis/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/viridisLite/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/whisker/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/withr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/workflowr/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/xfun/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/xtable/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/yaml/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/zeallot/
    Ignored:    packrat/lib/x86_64-pc-linux-gnu/3.6.1/zip/
    Ignored:    packrat/src/
    Ignored:    polymeRID.Rproj
    Ignored:    smp/20190812_1723_NNET/files/
    Ignored:    smp/20190812_1723_NNET/plots/
    Ignored:    smp/20190812_1729_NNET/files/
    Ignored:    smp/20190812_1729_NNET/plots/
    Ignored:    smp/20190812_1731_NNET/files/
    Ignored:    smp/20190812_1731_NNET/plots/
    Ignored:    smp/20190812_1733_NNET/files/
    Ignored:    smp/20190812_1733_NNET/plots/
    Ignored:    website/analysis/
    Ignored:    website/code/
    Ignored:    website/docs/
    Ignored:    website/output/
    Ignored:    website/run/
    Ignored:    website/smp/

Untracked files:
    Untracked:  analysis/cnn_calibration.Rmd
    Untracked:  analysis/cnn_exploration.Rmd
    Untracked:  code/cnn_cv_K70.R
    Untracked:  docs/figure/
    Untracked:  website/mod/

Unstaged changes:
    Modified:   code/functions.R
    Modified:   code/nnet.R
    Deleted:    website/ref/reference_Nylon.csv

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">
<p>
There are no past versions. Publish this analysis with <code>wflow_publish()</code> to start tracking its development.
</p>
<hr>
</div>
</div>
</div>
<p>Now, we want to test for the generalization potential of a CNN trained with the parameters mentioned above. For this, we also perform a 10-fold cross-validation which we are going to repeat 5 times.</p>
<pre class="r"><code>data = read.csv(file = paste0(ref, &quot;reference_database.csv&quot;), header = TRUE)

kernel = 70
folds = 10
repeats = 5
p = 0.5
nOutcome = length(unique(data$class))

sg.data = preprocess(data[,1:ncol(data)-1], type = &quot;norm&quot;)
sg.data$class = data$class
# preparing data inputs
set.seed(42)
foldIndex = lapply(1:repeats, caret::createDataPartition, y=sg.data$class, times = folds, p=p)
foldIndex = do.call(c,foldIndex)

cvData = list()
for (rep in 1:repeats){
  rep_Index = foldIndex[(rep*folds-folds+1):(rep*folds)] #always jump to the correct number of folds forward for each repeat
  
  dataFold = lapply(1:folds,function(x){
    
    training = sg.data[unlist(rep_Index[x]), ]
    validation = sg.data[-unlist(rep_Index[x]), ]
    foldtmp = list(training,validation)
    names(foldtmp) = c(&quot;training&quot;,&quot;validation&quot;)
    return(foldtmp)
  })
  cvData[[rep]] = dataFold
}
results = data.frame(repeats = rep(0,repeats*folds),
                     fold = rep(0,repeats*folds),
                     loss = rep(0,repeats*folds),
                     acc = rep(0,repeats*folds))
counter = 1
for (rep in 1:repeats){
  #print(paste0(&quot;Starting repeat &quot;,rep,&quot; out of &quot;,repeats,&quot;.&quot;))
  for (fold in 1:folds){
    
    variables = ncol(cvData[[rep]][[fold]][[1]])-1
    x_train = cvData[[rep]][[fold]][[&quot;training&quot;]][,1:variables]
    y_train = unlist(cvData[[rep]][[fold]][[&quot;training&quot;]][1+variables])
    x_test = cvData[[rep]][[fold]][[&quot;validation&quot;]][,1:variables]
    y_test = unlist(cvData[[rep]][[fold]][[&quot;validation&quot;]][1+variables])
    
    # function to get keras array for dataframes
    K &lt;- keras::backend()
    df_to_karray &lt;- function(df){
      tmp = as.matrix(df)
      tmp = K$expand_dims(tmp, axis = 2L)
      tmp = K$eval(tmp)
    }
    
    # coerce data to keras structure
    x_train = df_to_karray(x_train)
    x_test = df_to_karray(x_test)
    y_train = keras::to_categorical(as.numeric(y_train)-1,nOutcome)
    y_test = keras::to_categorical(as.numeric(y_test)-1,nOutcome)
    
    # fitting the model
    kernelMod = prepNNET(kernel, variables, nOutcome = nOutcome)
    historyMod =  keras::fit(kernelMod, x = x_train, y = y_train,
                             epochs=300,
                             batch_size = 10 )
    
    evalK = keras::evaluate(kernelMod, x=x_test, y=y_test)
    results$repeats[counter] = rep
    results$fold[counter] = fold
    results$loss[counter] = evalK$loss
    results$acc[counter] = evalK$acc
    print(results[counter,])
    counter = counter + 1
    write.csv(results, file = paste0(output,&quot;nnet/cv/cvResults_K&quot;,kernel,&quot;.csv&quot;))
  }
}</code></pre>
<p>We can retrive information about the accurcies for the individual repeats and for the whole cross-validation by calculating average values.</p>
<pre class="r"><code>repResults = aggregate(acc ~ repeats ,results,mean)
dvResult = mean(results$acc)</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">repeats</th>
<th align="right">acc</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.8500000</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.8485714</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">0.8757143</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">0.8428571</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">0.8600000</td>
</tr>
</tbody>
</table>
<pre><code>The overall accuracy for the CNN is 0.86.</code></pre>
<p>Finally, we create a CNN based on the complete data set and save it to disk for future classifications</p>
<pre class="r"><code>K = keras::backend()
x_train = as.matrix(sg.data[,1:ncol(sg.data)-1])
x = K$expand_dims(x_train, axis = 2L)
x_train = K$eval(x)
y_train = keras::to_categorical(as.numeric(sg.data$class)-1, nOutcome)


model = prepNNET(kernel = 70, variables = ncol(sg.data)-1, nOutcome = length(unique(sg.data$class)))
history = fit(model, x = x_train, y = y_train, batch_size = 10, epochs = 300)

keras::save_model_hdf5(model, filepath = paste0(mod,&quot;BASE/cnnModel.hdf&quot;))</code></pre>
<p>Again, we can look at the training history to get an idea of the training process.</p>
<pre><code>Trained on 147 samples (batch_size=10, epochs=300)
Final epoch (plot to see history):
loss: 0.03969
 acc: 0.9796 </code></pre>
<div id="htmlwidget-5e9d4804ca425d337524" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-5e9d4804ca425d337524">{"x":{"data":[{"x":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],"y":[2.46427594885534,2.40637225358665,2.33207535743713,2.28273481414432,2.09253314238827,1.89009958465083,1.92614804319784,1.72058460015018,1.85149866788566,1.343966558677,1.3953820888688,1.29763302105625,1.36573295690575,1.20855437492838,1.06598277156856,1.07892851521369,0.909197237215886,1.09626458007462,0.9379047236475,0.9195786742937,0.871575537182036,0.786066930614361,0.741178376942265,0.807927474278171,0.889912956831407,0.748430346550585,0.682017229953591,0.73302001936906,0.854326337145097,0.62390436100311,0.703068665703949,0.560036926954782,0.707361677065999,0.607557086109304,0.746925943968247,0.611094579404714,0.453900074598943,0.589583831984981,0.525937895385586,0.486738503283384,0.604567000452353,0.468620348442979,0.440731358974158,0.473953543268904,0.464855197335587,0.451024000741998,0.383040410523512,0.53675295539251,0.429949108232446,0.41465866585978,0.468519309497609,0.421070223053296,0.419944608241928,0.370437471690227,0.39145578479483,0.333681899369979,0.318689078193944,0.311596748222705,0.35020973366134,0.350905046475177,0.317390756086022,0.326163079260158,0.315139516807941,0.388092435642976,0.296537746276174,0.405315036422947,0.335710716744264,0.4471233969643,0.428356358185917,0.310590434920828,0.440154074608874,0.272872232762324,0.494191211141443,0.367436341485199,0.293557082511941,0.343482918277079,0.265597560880136,0.351970546910552,0.322577998751686,0.273545805897032,0.21324166422393,0.247238498105078,0.244541207797268,0.268766814703439,0.320334524118981,0.235452709225368,0.166427712369596,0.163811915433731,0.15950388324504,0.2211669637017,0.22470724136651,0.294744119529619,0.273897337138045,0.282282562837714,0.337529575084748,0.328688317415666,0.263956285126152,0.236525316215849,0.215165604672515,0.172944347646569,0.192439587748781,0.161610732970088,0.137964481044383,0.157043106765265,0.179786877313844,0.133617233890457,0.158861116740574,0.213995181220476,0.18101516258301,0.191849114766129,0.132104561794042,0.240401376764208,0.210019599823725,0.361076902775537,0.312171319106809,0.268738385872776,0.189548236881795,0.261498430781827,0.283568950737415,0.183545405708798,0.182417751524319,0.227994089629374,0.18366815760529,0.117593520530024,0.194650781714693,0.222511155467455,0.300577543777268,0.270901493001159,0.283643466477491,0.249682099748479,0.2227583387043,0.184043526307357,0.239474632251425,0.135207115398517,0.208868816190836,0.251908895401221,0.182538930668819,0.255847706191787,0.16184833181664,0.111503347209623,0.120120746340146,0.0986574733448468,0.134544596095018,0.164949344534452,0.147553458607116,0.154228771111744,0.156659428324854,0.154122826114272,0.177860026889272,0.244408205937163,0.116773255802944,0.0962391789989913,0.0815492667143746,0.171321127621131,0.167335927271012,0.132219277677082,0.0824619216613193,0.232668639421241,0.438208063370643,0.251922332307919,0.124558938755876,0.173796529311459,0.184282554212964,0.228069092546191,0.146400761796909,0.102497097842877,0.12142036581526,0.150190891229174,0.0941041161901742,0.096775069294282,0.118752153438269,0.121650402814302,0.1655875240923,0.581308530706938,0.386822632786368,0.221633133307403,0.218380832373082,0.306070589916591,0.177625469533967,0.177090173169058,0.289350876850741,0.129661731421947,0.196151593395946,0.171570594859671,0.160632757964183,0.194286990175847,0.144602315592244,0.207021803297356,0.156830357577728,0.134736520067161,0.107785675034789,0.0488411263169936,0.0836980412809216,0.163604323144014,0.0590383915078579,0.0720424436153147,0.307903174589686,0.169257716819023,0.0687859535350331,0.120199631570148,0.106558245389729,0.133435313735588,0.11205994511549,0.0638937044090458,0.0858718637205965,0.130745657436157,0.0981405330790194,0.126287003537184,0.155659451928674,0.15817115561986,0.123250925368598,0.110614300914565,0.175145189714979,0.155510081142998,0.144711846625116,0.131178801741885,0.161671844830572,0.0942915890256551,0.0892453467486059,0.0657155480691973,0.0187934315736067,0.081009673028725,0.0728265988627816,0.105196081568447,0.164679485029299,0.290833093973548,0.123045255451425,0.116162202247738,0.12636088350952,0.222549046388967,0.137225994099008,0.0509484404845315,0.0752491957641074,0.177576668363312,0.0955997720379762,0.197433101969967,0.088024876112131,0.120673666066699,0.251328650089044,0.113949193196295,0.143469179223361,0.218246147594871,0.219692599373635,0.193442317346732,0.102431958805782,0.10070191027888,0.0805811160719212,0.0938331165579053,0.0695262157412081,0.161180951665821,0.0832589999214785,0.0374180992604328,0.0274780374653891,0.125882949551796,0.0639712276802222,0.0738971460924237,0.0771910433711319,0.0981787909434072,0.13696366003366,0.0849209159508119,0.11172869654933,0.0839628769959114,0.11001134686403,0.105496780721049,0.204852590098032,0.183408894023753,0.182338964776928,0.286651420654083,0.209937536010367,0.106209257326159,0.0994737560360257,0.122598197038735,0.0590472205246634,0.0545207651547429,0.101780676130692,0.0755199174179702,0.0495189264334333,0.0415561480422308,0.10564673099141,0.0506720629280756,0.0685266020951704,0.0418072393873618,0.0423629863503358,0.108507012065126,0.0460785721762248,0.0680501419735271,0.0248985948693641,0.0397059793894292,0.0468568308696667,0.0418872094501703,0.051289618113193,0.0563927984265468,0.0510207344564058,0.0726886423539091,0.0216484804912732,0.0127822232331097,0.0411242495048954,0.022709402040504,0.0709817551086707,0.0396911927315147],"text":["epoch:   1<br />value: 2.46427595","epoch:   2<br />value: 2.40637225","epoch:   3<br />value: 2.33207536","epoch:   4<br />value: 2.28273481","epoch:   5<br />value: 2.09253314","epoch:   6<br />value: 1.89009958","epoch:   7<br />value: 1.92614804","epoch:   8<br />value: 1.72058460","epoch:   9<br />value: 1.85149867","epoch:  10<br />value: 1.34396656","epoch:  11<br />value: 1.39538209","epoch:  12<br />value: 1.29763302","epoch:  13<br />value: 1.36573296","epoch:  14<br />value: 1.20855437","epoch:  15<br />value: 1.06598277","epoch:  16<br />value: 1.07892852","epoch:  17<br />value: 0.90919724","epoch:  18<br />value: 1.09626458","epoch:  19<br />value: 0.93790472","epoch:  20<br />value: 0.91957867","epoch:  21<br />value: 0.87157554","epoch:  22<br />value: 0.78606693","epoch:  23<br />value: 0.74117838","epoch:  24<br />value: 0.80792747","epoch:  25<br />value: 0.88991296","epoch:  26<br />value: 0.74843035","epoch:  27<br />value: 0.68201723","epoch:  28<br />value: 0.73302002","epoch:  29<br />value: 0.85432634","epoch:  30<br />value: 0.62390436","epoch:  31<br />value: 0.70306867","epoch:  32<br />value: 0.56003693","epoch:  33<br />value: 0.70736168","epoch:  34<br />value: 0.60755709","epoch:  35<br />value: 0.74692594","epoch:  36<br />value: 0.61109458","epoch:  37<br />value: 0.45390007","epoch:  38<br />value: 0.58958383","epoch:  39<br />value: 0.52593790","epoch:  40<br />value: 0.48673850","epoch:  41<br />value: 0.60456700","epoch:  42<br />value: 0.46862035","epoch:  43<br />value: 0.44073136","epoch:  44<br />value: 0.47395354","epoch:  45<br />value: 0.46485520","epoch:  46<br />value: 0.45102400","epoch:  47<br />value: 0.38304041","epoch:  48<br />value: 0.53675296","epoch:  49<br />value: 0.42994911","epoch:  50<br />value: 0.41465867","epoch:  51<br />value: 0.46851931","epoch:  52<br />value: 0.42107022","epoch:  53<br />value: 0.41994461","epoch:  54<br />value: 0.37043747","epoch:  55<br />value: 0.39145578","epoch:  56<br />value: 0.33368190","epoch:  57<br />value: 0.31868908","epoch:  58<br />value: 0.31159675","epoch:  59<br />value: 0.35020973","epoch:  60<br />value: 0.35090505","epoch:  61<br />value: 0.31739076","epoch:  62<br />value: 0.32616308","epoch:  63<br />value: 0.31513952","epoch:  64<br />value: 0.38809244","epoch:  65<br />value: 0.29653775","epoch:  66<br />value: 0.40531504","epoch:  67<br />value: 0.33571072","epoch:  68<br />value: 0.44712340","epoch:  69<br />value: 0.42835636","epoch:  70<br />value: 0.31059043","epoch:  71<br />value: 0.44015407","epoch:  72<br />value: 0.27287223","epoch:  73<br />value: 0.49419121","epoch:  74<br />value: 0.36743634","epoch:  75<br />value: 0.29355708","epoch:  76<br />value: 0.34348292","epoch:  77<br />value: 0.26559756","epoch:  78<br />value: 0.35197055","epoch:  79<br />value: 0.32257800","epoch:  80<br />value: 0.27354581","epoch:  81<br />value: 0.21324166","epoch:  82<br />value: 0.24723850","epoch:  83<br />value: 0.24454121","epoch:  84<br />value: 0.26876681","epoch:  85<br />value: 0.32033452","epoch:  86<br />value: 0.23545271","epoch:  87<br />value: 0.16642771","epoch:  88<br />value: 0.16381192","epoch:  89<br />value: 0.15950388","epoch:  90<br />value: 0.22116696","epoch:  91<br />value: 0.22470724","epoch:  92<br />value: 0.29474412","epoch:  93<br />value: 0.27389734","epoch:  94<br />value: 0.28228256","epoch:  95<br />value: 0.33752958","epoch:  96<br />value: 0.32868832","epoch:  97<br />value: 0.26395629","epoch:  98<br />value: 0.23652532","epoch:  99<br />value: 0.21516560","epoch: 100<br />value: 0.17294435","epoch: 101<br />value: 0.19243959","epoch: 102<br />value: 0.16161073","epoch: 103<br />value: 0.13796448","epoch: 104<br />value: 0.15704311","epoch: 105<br />value: 0.17978688","epoch: 106<br />value: 0.13361723","epoch: 107<br />value: 0.15886112","epoch: 108<br />value: 0.21399518","epoch: 109<br />value: 0.18101516","epoch: 110<br />value: 0.19184911","epoch: 111<br />value: 0.13210456","epoch: 112<br />value: 0.24040138","epoch: 113<br />value: 0.21001960","epoch: 114<br />value: 0.36107690","epoch: 115<br />value: 0.31217132","epoch: 116<br />value: 0.26873839","epoch: 117<br />value: 0.18954824","epoch: 118<br />value: 0.26149843","epoch: 119<br />value: 0.28356895","epoch: 120<br />value: 0.18354541","epoch: 121<br />value: 0.18241775","epoch: 122<br />value: 0.22799409","epoch: 123<br />value: 0.18366816","epoch: 124<br />value: 0.11759352","epoch: 125<br />value: 0.19465078","epoch: 126<br />value: 0.22251116","epoch: 127<br />value: 0.30057754","epoch: 128<br />value: 0.27090149","epoch: 129<br />value: 0.28364347","epoch: 130<br />value: 0.24968210","epoch: 131<br />value: 0.22275834","epoch: 132<br />value: 0.18404353","epoch: 133<br />value: 0.23947463","epoch: 134<br />value: 0.13520712","epoch: 135<br />value: 0.20886882","epoch: 136<br />value: 0.25190890","epoch: 137<br />value: 0.18253893","epoch: 138<br />value: 0.25584771","epoch: 139<br />value: 0.16184833","epoch: 140<br />value: 0.11150335","epoch: 141<br />value: 0.12012075","epoch: 142<br />value: 0.09865747","epoch: 143<br />value: 0.13454460","epoch: 144<br />value: 0.16494934","epoch: 145<br />value: 0.14755346","epoch: 146<br />value: 0.15422877","epoch: 147<br />value: 0.15665943","epoch: 148<br />value: 0.15412283","epoch: 149<br />value: 0.17786003","epoch: 150<br />value: 0.24440821","epoch: 151<br />value: 0.11677326","epoch: 152<br />value: 0.09623918","epoch: 153<br />value: 0.08154927","epoch: 154<br />value: 0.17132113","epoch: 155<br />value: 0.16733593","epoch: 156<br />value: 0.13221928","epoch: 157<br />value: 0.08246192","epoch: 158<br />value: 0.23266864","epoch: 159<br />value: 0.43820806","epoch: 160<br />value: 0.25192233","epoch: 161<br />value: 0.12455894","epoch: 162<br />value: 0.17379653","epoch: 163<br />value: 0.18428255","epoch: 164<br />value: 0.22806909","epoch: 165<br />value: 0.14640076","epoch: 166<br />value: 0.10249710","epoch: 167<br />value: 0.12142037","epoch: 168<br />value: 0.15019089","epoch: 169<br />value: 0.09410412","epoch: 170<br />value: 0.09677507","epoch: 171<br />value: 0.11875215","epoch: 172<br />value: 0.12165040","epoch: 173<br />value: 0.16558752","epoch: 174<br />value: 0.58130853","epoch: 175<br />value: 0.38682263","epoch: 176<br />value: 0.22163313","epoch: 177<br />value: 0.21838083","epoch: 178<br />value: 0.30607059","epoch: 179<br />value: 0.17762547","epoch: 180<br />value: 0.17709017","epoch: 181<br />value: 0.28935088","epoch: 182<br />value: 0.12966173","epoch: 183<br />value: 0.19615159","epoch: 184<br />value: 0.17157059","epoch: 185<br />value: 0.16063276","epoch: 186<br />value: 0.19428699","epoch: 187<br />value: 0.14460232","epoch: 188<br />value: 0.20702180","epoch: 189<br />value: 0.15683036","epoch: 190<br />value: 0.13473652","epoch: 191<br />value: 0.10778568","epoch: 192<br />value: 0.04884113","epoch: 193<br />value: 0.08369804","epoch: 194<br />value: 0.16360432","epoch: 195<br />value: 0.05903839","epoch: 196<br />value: 0.07204244","epoch: 197<br />value: 0.30790317","epoch: 198<br />value: 0.16925772","epoch: 199<br />value: 0.06878595","epoch: 200<br />value: 0.12019963","epoch: 201<br />value: 0.10655825","epoch: 202<br />value: 0.13343531","epoch: 203<br />value: 0.11205995","epoch: 204<br />value: 0.06389370","epoch: 205<br />value: 0.08587186","epoch: 206<br />value: 0.13074566","epoch: 207<br />value: 0.09814053","epoch: 208<br />value: 0.12628700","epoch: 209<br />value: 0.15565945","epoch: 210<br />value: 0.15817116","epoch: 211<br />value: 0.12325093","epoch: 212<br />value: 0.11061430","epoch: 213<br />value: 0.17514519","epoch: 214<br />value: 0.15551008","epoch: 215<br />value: 0.14471185","epoch: 216<br />value: 0.13117880","epoch: 217<br />value: 0.16167184","epoch: 218<br />value: 0.09429159","epoch: 219<br />value: 0.08924535","epoch: 220<br />value: 0.06571555","epoch: 221<br />value: 0.01879343","epoch: 222<br />value: 0.08100967","epoch: 223<br />value: 0.07282660","epoch: 224<br />value: 0.10519608","epoch: 225<br />value: 0.16467949","epoch: 226<br />value: 0.29083309","epoch: 227<br />value: 0.12304526","epoch: 228<br />value: 0.11616220","epoch: 229<br />value: 0.12636088","epoch: 230<br />value: 0.22254905","epoch: 231<br />value: 0.13722599","epoch: 232<br />value: 0.05094844","epoch: 233<br />value: 0.07524920","epoch: 234<br />value: 0.17757667","epoch: 235<br />value: 0.09559977","epoch: 236<br />value: 0.19743310","epoch: 237<br />value: 0.08802488","epoch: 238<br />value: 0.12067367","epoch: 239<br />value: 0.25132865","epoch: 240<br />value: 0.11394919","epoch: 241<br />value: 0.14346918","epoch: 242<br />value: 0.21824615","epoch: 243<br />value: 0.21969260","epoch: 244<br />value: 0.19344232","epoch: 245<br />value: 0.10243196","epoch: 246<br />value: 0.10070191","epoch: 247<br />value: 0.08058112","epoch: 248<br />value: 0.09383312","epoch: 249<br />value: 0.06952622","epoch: 250<br />value: 0.16118095","epoch: 251<br />value: 0.08325900","epoch: 252<br />value: 0.03741810","epoch: 253<br />value: 0.02747804","epoch: 254<br />value: 0.12588295","epoch: 255<br />value: 0.06397123","epoch: 256<br />value: 0.07389715","epoch: 257<br />value: 0.07719104","epoch: 258<br />value: 0.09817879","epoch: 259<br />value: 0.13696366","epoch: 260<br />value: 0.08492092","epoch: 261<br />value: 0.11172870","epoch: 262<br />value: 0.08396288","epoch: 263<br />value: 0.11001135","epoch: 264<br />value: 0.10549678","epoch: 265<br />value: 0.20485259","epoch: 266<br />value: 0.18340889","epoch: 267<br />value: 0.18233896","epoch: 268<br />value: 0.28665142","epoch: 269<br />value: 0.20993754","epoch: 270<br />value: 0.10620926","epoch: 271<br />value: 0.09947376","epoch: 272<br />value: 0.12259820","epoch: 273<br />value: 0.05904722","epoch: 274<br />value: 0.05452077","epoch: 275<br />value: 0.10178068","epoch: 276<br />value: 0.07551992","epoch: 277<br />value: 0.04951893","epoch: 278<br />value: 0.04155615","epoch: 279<br />value: 0.10564673","epoch: 280<br />value: 0.05067206","epoch: 281<br />value: 0.06852660","epoch: 282<br />value: 0.04180724","epoch: 283<br />value: 0.04236299","epoch: 284<br />value: 0.10850701","epoch: 285<br />value: 0.04607857","epoch: 286<br />value: 0.06805014","epoch: 287<br />value: 0.02489859","epoch: 288<br />value: 0.03970598","epoch: 289<br />value: 0.04685683","epoch: 290<br />value: 0.04188721","epoch: 291<br />value: 0.05128962","epoch: 292<br />value: 0.05639280","epoch: 293<br />value: 0.05102073","epoch: 294<br />value: 0.07268864","epoch: 295<br />value: 0.02164848","epoch: 296<br />value: 0.01278222","epoch: 297<br />value: 0.04112425","epoch: 298<br />value: 0.02270940","epoch: 299<br />value: 0.07098176","epoch: 300<br />value: 0.03969119"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"transparent","opacity":1,"size":5.66929133858268,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300],"y":[0.095238097012043,0.129251703619957,0.210884347558022,0.224489793181419,0.258503407239914,0.326530605554581,0.306122452020645,0.380952388048172,0.380952388048172,0.544217705726624,0.510204076766968,0.59863942861557,0.564625859260559,0.578231275081635,0.639455795288086,0.639455795288086,0.727891147136688,0.700680255889893,0.700680255889893,0.748299300670624,0.721088409423828,0.78231292963028,0.78231292963028,0.734693884849548,0.714285731315613,0.748299300670624,0.741496622562408,0.741496622562408,0.659863948822021,0.761904776096344,0.761904776096344,0.78911566734314,0.761904776096344,0.768707454204559,0.727891147136688,0.809523820877075,0.836734712123871,0.768707454204559,0.809523820877075,0.829931974411011,0.755102038383484,0.823129236698151,0.857142865657806,0.829931974411011,0.816326558589935,0.795918345451355,0.877551019191742,0.795918345451355,0.850340127944946,0.870748281478882,0.836734712123871,0.850340127944946,0.816326558589935,0.850340127944946,0.863945603370667,0.850340127944946,0.863945603370667,0.897959172725677,0.863945603370667,0.870748281478882,0.863945603370667,0.877551019191742,0.870748281478882,0.857142865657806,0.904761910438538,0.829931974411011,0.870748281478882,0.850340127944946,0.802721083164215,0.857142865657806,0.843537390232086,0.911564648151398,0.843537390232086,0.857142865657806,0.884353756904602,0.870748281478882,0.891156435012817,0.857142865657806,0.863945603370667,0.877551019191742,0.918367326259613,0.911564648151398,0.911564648151398,0.918367326259613,0.884353756904602,0.925170063972473,0.925170063972473,0.938775539398193,0.931972801685333,0.897959172725677,0.931972801685333,0.931972801685333,0.904761910438538,0.918367326259613,0.891156435012817,0.870748281478882,0.884353756904602,0.925170063972473,0.911564648151398,0.945578217506409,0.918367326259613,0.945578217506409,0.945578217506409,0.952380955219269,0.945578217506409,0.938775539398193,0.938775539398193,0.938775539398193,0.945578217506409,0.952380955219269,0.959183692932129,0.938775539398193,0.918367326259613,0.863945603370667,0.884353756904602,0.911564648151398,0.931972801685333,0.911564648151398,0.877551019191742,0.938775539398193,0.945578217506409,0.891156435012817,0.918367326259613,0.952380955219269,0.931972801685333,0.925170063972473,0.904761910438538,0.918367326259613,0.857142865657806,0.904761910438538,0.897959172725677,0.931972801685333,0.952380955219269,0.972789108753204,0.925170063972473,0.897959172725677,0.931972801685333,0.931972801685333,0.952380955219269,0.972789108753204,0.952380955219269,0.972789108753204,0.959183692932129,0.938775539398193,0.945578217506409,0.938775539398193,0.931972801685333,0.945578217506409,0.938775539398193,0.925170063972473,0.965986371040344,0.965986371040344,0.972789108753204,0.945578217506409,0.938775539398193,0.945578217506409,0.965986371040344,0.931972801685333,0.918367326259613,0.911564648151398,0.938775539398193,0.938775539398193,0.938775539398193,0.931972801685333,0.945578217506409,0.965986371040344,0.952380955219269,0.952380955219269,0.972789108753204,0.965986371040344,0.938775539398193,0.972789108753204,0.959183692932129,0.843537390232086,0.836734712123871,0.891156435012817,0.911564648151398,0.938775539398193,0.938775539398193,0.965986371040344,0.884353756904602,0.965986371040344,0.925170063972473,0.938775539398193,0.959183692932129,0.918367326259613,0.945578217506409,0.911564648151398,0.952380955219269,0.959183692932129,0.972789108753204,0.99319726228714,0.965986371040344,0.945578217506409,0.979591846466064,0.972789108753204,0.938775539398193,0.959183692932129,0.986394584178925,0.952380955219269,0.945578217506409,0.965986371040344,0.965986371040344,0.979591846466064,0.965986371040344,0.952380955219269,0.972789108753204,0.952380955219269,0.959183692932129,0.952380955219269,0.959183692932129,0.959183692932129,0.931972801685333,0.972789108753204,0.952380955219269,0.952380955219269,0.952380955219269,0.979591846466064,0.965986371040344,0.972789108753204,1,0.965986371040344,0.959183692932129,0.945578217506409,0.959183692932129,0.911564648151398,0.965986371040344,0.959183692932129,0.959183692932129,0.925170063972473,0.938775539398193,1,0.972789108753204,0.931972801685333,0.965986371040344,0.931972801685333,0.965986371040344,0.945578217506409,0.925170063972473,0.959183692932129,0.945578217506409,0.925170063972473,0.918367326259613,0.945578217506409,0.972789108753204,0.972789108753204,0.959183692932129,0.972789108753204,0.99319726228714,0.931972801685333,0.986394584178925,0.986394584178925,1,0.972789108753204,0.986394584178925,0.972789108753204,0.986394584178925,0.972789108753204,0.965986371040344,0.979591846466064,0.945578217506409,0.965986371040344,0.959183692932129,0.965986371040344,0.918367326259613,0.945578217506409,0.931972801685333,0.945578217506409,0.918367326259613,0.979591846466064,0.972789108753204,0.979591846466064,0.986394584178925,0.99319726228714,0.965986371040344,0.979591846466064,0.986394584178925,0.99319726228714,0.959183692932129,0.979591846466064,0.972789108753204,1,0.979591846466064,0.965986371040344,0.99319726228714,0.979591846466064,1,0.979591846466064,0.986394584178925,0.99319726228714,0.979591846466064,0.986394584178925,0.979591846466064,0.979591846466064,1,1,0.979591846466064,1,0.99319726228714,0.979591846466064],"text":["epoch:   1<br />value: 0.09523810","epoch:   2<br />value: 0.12925170","epoch:   3<br />value: 0.21088435","epoch:   4<br />value: 0.22448979","epoch:   5<br />value: 0.25850341","epoch:   6<br />value: 0.32653061","epoch:   7<br />value: 0.30612245","epoch:   8<br />value: 0.38095239","epoch:   9<br />value: 0.38095239","epoch:  10<br />value: 0.54421771","epoch:  11<br />value: 0.51020408","epoch:  12<br />value: 0.59863943","epoch:  13<br />value: 0.56462586","epoch:  14<br />value: 0.57823128","epoch:  15<br />value: 0.63945580","epoch:  16<br />value: 0.63945580","epoch:  17<br />value: 0.72789115","epoch:  18<br />value: 0.70068026","epoch:  19<br />value: 0.70068026","epoch:  20<br />value: 0.74829930","epoch:  21<br />value: 0.72108841","epoch:  22<br />value: 0.78231293","epoch:  23<br />value: 0.78231293","epoch:  24<br />value: 0.73469388","epoch:  25<br />value: 0.71428573","epoch:  26<br />value: 0.74829930","epoch:  27<br />value: 0.74149662","epoch:  28<br />value: 0.74149662","epoch:  29<br />value: 0.65986395","epoch:  30<br />value: 0.76190478","epoch:  31<br />value: 0.76190478","epoch:  32<br />value: 0.78911567","epoch:  33<br />value: 0.76190478","epoch:  34<br />value: 0.76870745","epoch:  35<br />value: 0.72789115","epoch:  36<br />value: 0.80952382","epoch:  37<br />value: 0.83673471","epoch:  38<br />value: 0.76870745","epoch:  39<br />value: 0.80952382","epoch:  40<br />value: 0.82993197","epoch:  41<br />value: 0.75510204","epoch:  42<br />value: 0.82312924","epoch:  43<br />value: 0.85714287","epoch:  44<br />value: 0.82993197","epoch:  45<br />value: 0.81632656","epoch:  46<br />value: 0.79591835","epoch:  47<br />value: 0.87755102","epoch:  48<br />value: 0.79591835","epoch:  49<br />value: 0.85034013","epoch:  50<br />value: 0.87074828","epoch:  51<br />value: 0.83673471","epoch:  52<br />value: 0.85034013","epoch:  53<br />value: 0.81632656","epoch:  54<br />value: 0.85034013","epoch:  55<br />value: 0.86394560","epoch:  56<br />value: 0.85034013","epoch:  57<br />value: 0.86394560","epoch:  58<br />value: 0.89795917","epoch:  59<br />value: 0.86394560","epoch:  60<br />value: 0.87074828","epoch:  61<br />value: 0.86394560","epoch:  62<br />value: 0.87755102","epoch:  63<br />value: 0.87074828","epoch:  64<br />value: 0.85714287","epoch:  65<br />value: 0.90476191","epoch:  66<br />value: 0.82993197","epoch:  67<br />value: 0.87074828","epoch:  68<br />value: 0.85034013","epoch:  69<br />value: 0.80272108","epoch:  70<br />value: 0.85714287","epoch:  71<br />value: 0.84353739","epoch:  72<br />value: 0.91156465","epoch:  73<br />value: 0.84353739","epoch:  74<br />value: 0.85714287","epoch:  75<br />value: 0.88435376","epoch:  76<br />value: 0.87074828","epoch:  77<br />value: 0.89115644","epoch:  78<br />value: 0.85714287","epoch:  79<br />value: 0.86394560","epoch:  80<br />value: 0.87755102","epoch:  81<br />value: 0.91836733","epoch:  82<br />value: 0.91156465","epoch:  83<br />value: 0.91156465","epoch:  84<br />value: 0.91836733","epoch:  85<br />value: 0.88435376","epoch:  86<br />value: 0.92517006","epoch:  87<br />value: 0.92517006","epoch:  88<br />value: 0.93877554","epoch:  89<br />value: 0.93197280","epoch:  90<br />value: 0.89795917","epoch:  91<br />value: 0.93197280","epoch:  92<br />value: 0.93197280","epoch:  93<br />value: 0.90476191","epoch:  94<br />value: 0.91836733","epoch:  95<br />value: 0.89115644","epoch:  96<br />value: 0.87074828","epoch:  97<br />value: 0.88435376","epoch:  98<br />value: 0.92517006","epoch:  99<br />value: 0.91156465","epoch: 100<br />value: 0.94557822","epoch: 101<br />value: 0.91836733","epoch: 102<br />value: 0.94557822","epoch: 103<br />value: 0.94557822","epoch: 104<br />value: 0.95238096","epoch: 105<br />value: 0.94557822","epoch: 106<br />value: 0.93877554","epoch: 107<br />value: 0.93877554","epoch: 108<br />value: 0.93877554","epoch: 109<br />value: 0.94557822","epoch: 110<br />value: 0.95238096","epoch: 111<br />value: 0.95918369","epoch: 112<br />value: 0.93877554","epoch: 113<br />value: 0.91836733","epoch: 114<br />value: 0.86394560","epoch: 115<br />value: 0.88435376","epoch: 116<br />value: 0.91156465","epoch: 117<br />value: 0.93197280","epoch: 118<br />value: 0.91156465","epoch: 119<br />value: 0.87755102","epoch: 120<br />value: 0.93877554","epoch: 121<br />value: 0.94557822","epoch: 122<br />value: 0.89115644","epoch: 123<br />value: 0.91836733","epoch: 124<br />value: 0.95238096","epoch: 125<br />value: 0.93197280","epoch: 126<br />value: 0.92517006","epoch: 127<br />value: 0.90476191","epoch: 128<br />value: 0.91836733","epoch: 129<br />value: 0.85714287","epoch: 130<br />value: 0.90476191","epoch: 131<br />value: 0.89795917","epoch: 132<br />value: 0.93197280","epoch: 133<br />value: 0.95238096","epoch: 134<br />value: 0.97278911","epoch: 135<br />value: 0.92517006","epoch: 136<br />value: 0.89795917","epoch: 137<br />value: 0.93197280","epoch: 138<br />value: 0.93197280","epoch: 139<br />value: 0.95238096","epoch: 140<br />value: 0.97278911","epoch: 141<br />value: 0.95238096","epoch: 142<br />value: 0.97278911","epoch: 143<br />value: 0.95918369","epoch: 144<br />value: 0.93877554","epoch: 145<br />value: 0.94557822","epoch: 146<br />value: 0.93877554","epoch: 147<br />value: 0.93197280","epoch: 148<br />value: 0.94557822","epoch: 149<br />value: 0.93877554","epoch: 150<br />value: 0.92517006","epoch: 151<br />value: 0.96598637","epoch: 152<br />value: 0.96598637","epoch: 153<br />value: 0.97278911","epoch: 154<br />value: 0.94557822","epoch: 155<br />value: 0.93877554","epoch: 156<br />value: 0.94557822","epoch: 157<br />value: 0.96598637","epoch: 158<br />value: 0.93197280","epoch: 159<br />value: 0.91836733","epoch: 160<br />value: 0.91156465","epoch: 161<br />value: 0.93877554","epoch: 162<br />value: 0.93877554","epoch: 163<br />value: 0.93877554","epoch: 164<br />value: 0.93197280","epoch: 165<br />value: 0.94557822","epoch: 166<br />value: 0.96598637","epoch: 167<br />value: 0.95238096","epoch: 168<br />value: 0.95238096","epoch: 169<br />value: 0.97278911","epoch: 170<br />value: 0.96598637","epoch: 171<br />value: 0.93877554","epoch: 172<br />value: 0.97278911","epoch: 173<br />value: 0.95918369","epoch: 174<br />value: 0.84353739","epoch: 175<br />value: 0.83673471","epoch: 176<br />value: 0.89115644","epoch: 177<br />value: 0.91156465","epoch: 178<br />value: 0.93877554","epoch: 179<br />value: 0.93877554","epoch: 180<br />value: 0.96598637","epoch: 181<br />value: 0.88435376","epoch: 182<br />value: 0.96598637","epoch: 183<br />value: 0.92517006","epoch: 184<br />value: 0.93877554","epoch: 185<br />value: 0.95918369","epoch: 186<br />value: 0.91836733","epoch: 187<br />value: 0.94557822","epoch: 188<br />value: 0.91156465","epoch: 189<br />value: 0.95238096","epoch: 190<br />value: 0.95918369","epoch: 191<br />value: 0.97278911","epoch: 192<br />value: 0.99319726","epoch: 193<br />value: 0.96598637","epoch: 194<br />value: 0.94557822","epoch: 195<br />value: 0.97959185","epoch: 196<br />value: 0.97278911","epoch: 197<br />value: 0.93877554","epoch: 198<br />value: 0.95918369","epoch: 199<br />value: 0.98639458","epoch: 200<br />value: 0.95238096","epoch: 201<br />value: 0.94557822","epoch: 202<br />value: 0.96598637","epoch: 203<br />value: 0.96598637","epoch: 204<br />value: 0.97959185","epoch: 205<br />value: 0.96598637","epoch: 206<br />value: 0.95238096","epoch: 207<br />value: 0.97278911","epoch: 208<br />value: 0.95238096","epoch: 209<br />value: 0.95918369","epoch: 210<br />value: 0.95238096","epoch: 211<br />value: 0.95918369","epoch: 212<br />value: 0.95918369","epoch: 213<br />value: 0.93197280","epoch: 214<br />value: 0.97278911","epoch: 215<br />value: 0.95238096","epoch: 216<br />value: 0.95238096","epoch: 217<br />value: 0.95238096","epoch: 218<br />value: 0.97959185","epoch: 219<br />value: 0.96598637","epoch: 220<br />value: 0.97278911","epoch: 221<br />value: 1.00000000","epoch: 222<br />value: 0.96598637","epoch: 223<br />value: 0.95918369","epoch: 224<br />value: 0.94557822","epoch: 225<br />value: 0.95918369","epoch: 226<br />value: 0.91156465","epoch: 227<br />value: 0.96598637","epoch: 228<br />value: 0.95918369","epoch: 229<br />value: 0.95918369","epoch: 230<br />value: 0.92517006","epoch: 231<br />value: 0.93877554","epoch: 232<br />value: 1.00000000","epoch: 233<br />value: 0.97278911","epoch: 234<br />value: 0.93197280","epoch: 235<br />value: 0.96598637","epoch: 236<br />value: 0.93197280","epoch: 237<br />value: 0.96598637","epoch: 238<br />value: 0.94557822","epoch: 239<br />value: 0.92517006","epoch: 240<br />value: 0.95918369","epoch: 241<br />value: 0.94557822","epoch: 242<br />value: 0.92517006","epoch: 243<br />value: 0.91836733","epoch: 244<br />value: 0.94557822","epoch: 245<br />value: 0.97278911","epoch: 246<br />value: 0.97278911","epoch: 247<br />value: 0.95918369","epoch: 248<br />value: 0.97278911","epoch: 249<br />value: 0.99319726","epoch: 250<br />value: 0.93197280","epoch: 251<br />value: 0.98639458","epoch: 252<br />value: 0.98639458","epoch: 253<br />value: 1.00000000","epoch: 254<br />value: 0.97278911","epoch: 255<br />value: 0.98639458","epoch: 256<br />value: 0.97278911","epoch: 257<br />value: 0.98639458","epoch: 258<br />value: 0.97278911","epoch: 259<br />value: 0.96598637","epoch: 260<br />value: 0.97959185","epoch: 261<br />value: 0.94557822","epoch: 262<br />value: 0.96598637","epoch: 263<br />value: 0.95918369","epoch: 264<br />value: 0.96598637","epoch: 265<br />value: 0.91836733","epoch: 266<br />value: 0.94557822","epoch: 267<br />value: 0.93197280","epoch: 268<br />value: 0.94557822","epoch: 269<br />value: 0.91836733","epoch: 270<br />value: 0.97959185","epoch: 271<br />value: 0.97278911","epoch: 272<br />value: 0.97959185","epoch: 273<br />value: 0.98639458","epoch: 274<br />value: 0.99319726","epoch: 275<br />value: 0.96598637","epoch: 276<br />value: 0.97959185","epoch: 277<br />value: 0.98639458","epoch: 278<br />value: 0.99319726","epoch: 279<br />value: 0.95918369","epoch: 280<br />value: 0.97959185","epoch: 281<br />value: 0.97278911","epoch: 282<br />value: 1.00000000","epoch: 283<br />value: 0.97959185","epoch: 284<br />value: 0.96598637","epoch: 285<br />value: 0.99319726","epoch: 286<br />value: 0.97959185","epoch: 287<br />value: 1.00000000","epoch: 288<br />value: 0.97959185","epoch: 289<br />value: 0.98639458","epoch: 290<br />value: 0.99319726","epoch: 291<br />value: 0.97959185","epoch: 292<br />value: 0.98639458","epoch: 293<br />value: 0.97959185","epoch: 294<br />value: 0.97959185","epoch: 295<br />value: 1.00000000","epoch: 296<br />value: 1.00000000","epoch: 297<br />value: 0.97959185","epoch: 298<br />value: 1.00000000","epoch: 299<br />value: 0.99319726","epoch: 300<br />value: 0.97959185"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"transparent","opacity":1,"size":5.66929133858268,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y2","hoverinfo":"text","frame":null},{"x":[1,4.78481012658228,8.56962025316456,12.3544303797468,16.1392405063291,19.9240506329114,23.7088607594937,27.493670886076,31.2784810126582,35.0632911392405,38.8481012658228,42.6329113924051,46.4177215189873,50.2025316455696,53.9873417721519,57.7721518987342,61.5569620253165,65.3417721518987,69.126582278481,72.9113924050633,76.6962025316456,80.4810126582279,84.2658227848101,88.0506329113924,91.8354430379747,95.620253164557,99.4050632911392,103.189873417722,106.974683544304,110.759493670886,114.544303797468,118.329113924051,122.113924050633,125.898734177215,129.683544303797,133.46835443038,137.253164556962,141.037974683544,144.822784810127,148.607594936709,152.392405063291,156.177215189873,159.962025316456,163.746835443038,167.53164556962,171.316455696203,175.101265822785,178.886075949367,182.670886075949,186.455696202532,190.240506329114,194.025316455696,197.810126582278,201.594936708861,205.379746835443,209.164556962025,212.949367088608,216.73417721519,220.518987341772,224.303797468354,228.088607594937,231.873417721519,235.658227848101,239.443037974684,243.227848101266,247.012658227848,250.79746835443,254.582278481013,258.367088607595,262.151898734177,265.936708860759,269.721518987342,273.506329113924,277.291139240506,281.075949367089,284.860759493671,288.645569620253,292.430379746835,296.215189873418,300],"y":[1.61812837161763,1.5180704938541,1.42124063486178,1.32773622332075,1.23765468791109,1.15109345731289,1.06814996020623,0.988921625271197,0.913505881187862,0.842000156636315,0.774507784364788,0.711204147099274,0.651967399672476,0.596572554063363,0.544794622250901,0.496408616214059,0.451189547931804,0.408912429383103,0.369352272546924,0.332284089402234,0.298145913844858,0.271287737330963,0.251515014442124,0.237575799054516,0.228218145044314,0.222190106287695,0.218239736660835,0.21511509003991,0.211564220301096,0.206335181320568,0.198733849979387,0.192725704831536,0.188940377929536,0.186877232631675,0.18603563229624,0.18591494028152,0.186014519945802,0.185833734647374,0.184871947744525,0.182628522595541,0.179122349611397,0.175940646667009,0.173161359047526,0.170695740593573,0.168455045145776,0.166350526544759,0.164293438631148,0.162195035245569,0.159966570228647,0.157519297421008,0.154870976518531,0.1523939910816,0.150074089126605,0.147847101066652,0.145648857314851,0.143415188284312,0.141081924388143,0.138584896039453,0.135859933651351,0.132842867636946,0.12958074175825,0.126259039393803,0.122878060445084,0.119432787691421,0.115918203912138,0.112329291886561,0.108661034394017,0.104908414213831,0.101066414125329,0.097130016907837,0.0930948562882038,0.0889613713474099,0.0847321434367085,0.0804097632857387,0.07599682162414,0.0714959091815514,0.0669096166876122,0.0622405348719616,0.0574912544642389,0.0526643661940831],"text":["epoch:   1.00000<br />value: 1.61812837","epoch:   4.78481<br />value: 1.51807049","epoch:   8.56962<br />value: 1.42124063","epoch:  12.35443<br />value: 1.32773622","epoch:  16.13924<br />value: 1.23765469","epoch:  19.92405<br />value: 1.15109346","epoch:  23.70886<br />value: 1.06814996","epoch:  27.49367<br />value: 0.98892163","epoch:  31.27848<br />value: 0.91350588","epoch:  35.06329<br />value: 0.84200016","epoch:  38.84810<br />value: 0.77450778","epoch:  42.63291<br />value: 0.71120415","epoch:  46.41772<br />value: 0.65196740","epoch:  50.20253<br />value: 0.59657255","epoch:  53.98734<br />value: 0.54479462","epoch:  57.77215<br />value: 0.49640862","epoch:  61.55696<br />value: 0.45118955","epoch:  65.34177<br />value: 0.40891243","epoch:  69.12658<br />value: 0.36935227","epoch:  72.91139<br />value: 0.33228409","epoch:  76.69620<br />value: 0.29814591","epoch:  80.48101<br />value: 0.27128774","epoch:  84.26582<br />value: 0.25151501","epoch:  88.05063<br />value: 0.23757580","epoch:  91.83544<br />value: 0.22821815","epoch:  95.62025<br />value: 0.22219011","epoch:  99.40506<br />value: 0.21823974","epoch: 103.18987<br />value: 0.21511509","epoch: 106.97468<br />value: 0.21156422","epoch: 110.75949<br />value: 0.20633518","epoch: 114.54430<br />value: 0.19873385","epoch: 118.32911<br />value: 0.19272570","epoch: 122.11392<br />value: 0.18894038","epoch: 125.89873<br />value: 0.18687723","epoch: 129.68354<br />value: 0.18603563","epoch: 133.46835<br />value: 0.18591494","epoch: 137.25316<br />value: 0.18601452","epoch: 141.03797<br />value: 0.18583373","epoch: 144.82278<br />value: 0.18487195","epoch: 148.60759<br />value: 0.18262852","epoch: 152.39241<br />value: 0.17912235","epoch: 156.17722<br />value: 0.17594065","epoch: 159.96203<br />value: 0.17316136","epoch: 163.74684<br />value: 0.17069574","epoch: 167.53165<br />value: 0.16845505","epoch: 171.31646<br />value: 0.16635053","epoch: 175.10127<br />value: 0.16429344","epoch: 178.88608<br />value: 0.16219504","epoch: 182.67089<br />value: 0.15996657","epoch: 186.45570<br />value: 0.15751930","epoch: 190.24051<br />value: 0.15487098","epoch: 194.02532<br />value: 0.15239399","epoch: 197.81013<br />value: 0.15007409","epoch: 201.59494<br />value: 0.14784710","epoch: 205.37975<br />value: 0.14564886","epoch: 209.16456<br />value: 0.14341519","epoch: 212.94937<br />value: 0.14108192","epoch: 216.73418<br />value: 0.13858490","epoch: 220.51899<br />value: 0.13585993","epoch: 224.30380<br />value: 0.13284287","epoch: 228.08861<br />value: 0.12958074","epoch: 231.87342<br />value: 0.12625904","epoch: 235.65823<br />value: 0.12287806","epoch: 239.44304<br />value: 0.11943279","epoch: 243.22785<br />value: 0.11591820","epoch: 247.01266<br />value: 0.11232929","epoch: 250.79747<br />value: 0.10866103","epoch: 254.58228<br />value: 0.10490841","epoch: 258.36709<br />value: 0.10106641","epoch: 262.15190<br />value: 0.09713002","epoch: 265.93671<br />value: 0.09309486","epoch: 269.72152<br />value: 0.08896137","epoch: 273.50633<br />value: 0.08473214","epoch: 277.29114<br />value: 0.08040976","epoch: 281.07595<br />value: 0.07599682","epoch: 284.86076<br />value: 0.07149591","epoch: 288.64557<br />value: 0.06690962","epoch: 292.43038<br />value: 0.06224053","epoch: 296.21519<br />value: 0.05749125","epoch: 300.00000<br />value: 0.05266437"],"type":"scatter","mode":"lines","name":"fitted values","line":{"width":3.77952755905512,"color":"rgba(51,102,255,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,4.78481012658228,8.56962025316456,12.3544303797468,16.1392405063291,19.9240506329114,23.7088607594937,27.493670886076,31.2784810126582,35.0632911392405,38.8481012658228,42.6329113924051,46.4177215189873,50.2025316455696,53.9873417721519,57.7721518987342,61.5569620253165,65.3417721518987,69.126582278481,72.9113924050633,76.6962025316456,80.4810126582279,84.2658227848101,88.0506329113924,91.8354430379747,95.620253164557,99.4050632911392,103.189873417722,106.974683544304,110.759493670886,114.544303797468,118.329113924051,122.113924050633,125.898734177215,129.683544303797,133.46835443038,137.253164556962,141.037974683544,144.822784810127,148.607594936709,152.392405063291,156.177215189873,159.962025316456,163.746835443038,167.53164556962,171.316455696203,175.101265822785,178.886075949367,182.670886075949,186.455696202532,190.240506329114,194.025316455696,197.810126582278,201.594936708861,205.379746835443,209.164556962025,212.949367088608,216.73417721519,220.518987341772,224.303797468354,228.088607594937,231.873417721519,235.658227848101,239.443037974684,243.227848101266,247.012658227848,250.79746835443,254.582278481013,258.367088607595,262.151898734177,265.936708860759,269.721518987342,273.506329113924,277.291139240506,281.075949367089,284.860759493671,288.645569620253,292.430379746835,296.215189873418,300],"y":[0.447076920751621,0.480447581956883,0.51275732528011,0.543973959214339,0.57406529225261,0.602999132887963,0.630743289613437,0.657265570922071,0.682533785306903,0.706515741260974,0.729177230641298,0.750458484183573,0.770398780353803,0.789072245633234,0.806553006503114,0.822915189444693,0.838232920939217,0.852580327467936,0.866031535512096,0.878660671552947,0.890326503979161,0.899617552768789,0.906599158844668,0.911680179506364,0.915269472053443,0.91777589378547,0.919608302002011,0.921175554002633,0.9228865070869,0.925150018554378,0.928196169944238,0.930755413503576,0.932615682946455,0.933926039618855,0.934835544866758,0.935493260036145,0.936048246472997,0.936649565523295,0.93744627853302,0.938587446848153,0.94005502539927,0.941338131772093,0.942425301804737,0.943359278056802,0.944182803087885,0.944938619457584,0.945669469725499,0.946418096451226,0.947227242194365,0.948139649514514,0.949150324256826,0.950092342178089,0.9509681861673,0.951802516463256,0.952619993304751,0.953445276930581,0.954303027579541,0.955217905490428,0.956214570902036,0.957317684053161,0.958507674772225,0.959710808808421,0.960927724404542,0.962161183640436,0.963413948595948,0.964688781350923,0.965988443985208,0.967315698578649,0.96867330721109,0.97006403196238,0.971489908408278,0.972949925281033,0.974442733744547,0.975967011372369,0.977521435738051,0.979104684415144,0.980715434977199,0.982352364997767,0.984014152050399,0.985699473708645],"text":["epoch:   1.00000<br />value: 0.44707692","epoch:   4.78481<br />value: 0.48044758","epoch:   8.56962<br />value: 0.51275733","epoch:  12.35443<br />value: 0.54397396","epoch:  16.13924<br />value: 0.57406529","epoch:  19.92405<br />value: 0.60299913","epoch:  23.70886<br />value: 0.63074329","epoch:  27.49367<br />value: 0.65726557","epoch:  31.27848<br />value: 0.68253379","epoch:  35.06329<br />value: 0.70651574","epoch:  38.84810<br />value: 0.72917723","epoch:  42.63291<br />value: 0.75045848","epoch:  46.41772<br />value: 0.77039878","epoch:  50.20253<br />value: 0.78907225","epoch:  53.98734<br />value: 0.80655301","epoch:  57.77215<br />value: 0.82291519","epoch:  61.55696<br />value: 0.83823292","epoch:  65.34177<br />value: 0.85258033","epoch:  69.12658<br />value: 0.86603154","epoch:  72.91139<br />value: 0.87866067","epoch:  76.69620<br />value: 0.89032650","epoch:  80.48101<br />value: 0.89961755","epoch:  84.26582<br />value: 0.90659916","epoch:  88.05063<br />value: 0.91168018","epoch:  91.83544<br />value: 0.91526947","epoch:  95.62025<br />value: 0.91777589","epoch:  99.40506<br />value: 0.91960830","epoch: 103.18987<br />value: 0.92117555","epoch: 106.97468<br />value: 0.92288651","epoch: 110.75949<br />value: 0.92515002","epoch: 114.54430<br />value: 0.92819617","epoch: 118.32911<br />value: 0.93075541","epoch: 122.11392<br />value: 0.93261568","epoch: 125.89873<br />value: 0.93392604","epoch: 129.68354<br />value: 0.93483554","epoch: 133.46835<br />value: 0.93549326","epoch: 137.25316<br />value: 0.93604825","epoch: 141.03797<br />value: 0.93664957","epoch: 144.82278<br />value: 0.93744628","epoch: 148.60759<br />value: 0.93858745","epoch: 152.39241<br />value: 0.94005503","epoch: 156.17722<br />value: 0.94133813","epoch: 159.96203<br />value: 0.94242530","epoch: 163.74684<br />value: 0.94335928","epoch: 167.53165<br />value: 0.94418280","epoch: 171.31646<br />value: 0.94493862","epoch: 175.10127<br />value: 0.94566947","epoch: 178.88608<br />value: 0.94641810","epoch: 182.67089<br />value: 0.94722724","epoch: 186.45570<br />value: 0.94813965","epoch: 190.24051<br />value: 0.94915032","epoch: 194.02532<br />value: 0.95009234","epoch: 197.81013<br />value: 0.95096819","epoch: 201.59494<br />value: 0.95180252","epoch: 205.37975<br />value: 0.95261999","epoch: 209.16456<br />value: 0.95344528","epoch: 212.94937<br />value: 0.95430303","epoch: 216.73418<br />value: 0.95521791","epoch: 220.51899<br />value: 0.95621457","epoch: 224.30380<br />value: 0.95731768","epoch: 228.08861<br />value: 0.95850767","epoch: 231.87342<br />value: 0.95971081","epoch: 235.65823<br />value: 0.96092772","epoch: 239.44304<br />value: 0.96216118","epoch: 243.22785<br />value: 0.96341395","epoch: 247.01266<br />value: 0.96468878","epoch: 250.79747<br />value: 0.96598844","epoch: 254.58228<br />value: 0.96731570","epoch: 258.36709<br />value: 0.96867331","epoch: 262.15190<br />value: 0.97006403","epoch: 265.93671<br />value: 0.97148991","epoch: 269.72152<br />value: 0.97294993","epoch: 273.50633<br />value: 0.97444273","epoch: 277.29114<br />value: 0.97596701","epoch: 281.07595<br />value: 0.97752144","epoch: 284.86076<br />value: 0.97910468","epoch: 288.64557<br />value: 0.98071543","epoch: 292.43038<br />value: 0.98235236","epoch: 296.21519<br />value: 0.98401415","epoch: 300.00000<br />value: 0.98569947"],"type":"scatter","mode":"lines","name":"fitted values","line":{"width":3.77952755905512,"color":"rgba(51,102,255,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y2","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":37.9178082191781,"r":18.9954337899543,"b":40.1826484018265,"l":43.1050228310502},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-13.95,314.95],"tickmode":"array","ticktext":["0","50","100","150","200","250","300"],"tickvals":[0,50,100,150,200,250,300],"categoryorder":"array","categoryarray":["0","50","100","150","200","250","300"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y2","title":"","hoverformat":".2f"},"annotations":[{"text":"epoch","x":0.5,"y":-0.0176940639269406,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"top","annotationType":"axis"},{"text":"value","x":-0.0159001956947162,"y":0.5,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xref":"paper","yref":"paper","textangle":-90,"xanchor":"right","yanchor":"center","annotationType":"axis"},{"text":"loss","x":1,"y":0.752853881278539,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":11.689497716895},"xref":"paper","yref":"paper","textangle":90,"xanchor":"left","yanchor":"middle"},{"text":"acc","x":1,"y":0.247146118721461,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":11.689497716895},"xref":"paper","yref":"paper","textangle":90,"xanchor":"left","yanchor":"middle"}],"yaxis":{"domain":[0.505707762557078,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.109792463048002,2.58685063513645],"tickmode":"array","ticktext":["0.0","0.5","1.0","1.5","2.0","2.5"],"tickvals":[0,0.5,1,1.5,2,2.5],"categoryorder":"array","categoryarray":["0.0","0.5","1.0","1.5","2.0","2.5"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":"","hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0.505707762557078,"y1":1},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","y0":0.505707762557078,"y1":1,"x0":0,"x1":23.37899543379,"xanchor":1,"xsizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":0.494292237442922},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","y0":0,"y1":0.494292237442922,"x0":0,"x1":23.37899543379,"xanchor":1,"xsizemode":"pixel"}],"yaxis2":{"type":"linear","autorange":false,"range":[0.0500000018626451,1.0452380951494],"tickmode":"array","ticktext":["0.25","0.50","0.75","1.00"],"tickvals":[0.25,0.5,0.75,1],"categoryorder":"array","categoryarray":["0.25","0.50","0.75","1.00"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,0.494292237442922],"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":"","hoverformat":".2f"},"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","showSendToCloud":false},"source":"A","attrs":{"49974c575ffd":{"x":{},"y":{},"type":"scatter"},"499754b755b3":{"x":{},"y":{}}},"cur_data":"49974c575ffd","visdat":{"49974c575ffd":["function (y) ","x"],"499754b755b3":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<div id="refs">

</div>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span> Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.6.1 (2019-07-05)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Linux Mint 19.1

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] tensorflow_1.14.0         abind_1.4-5              
 [3] e1071_1.7-2               keras_2.2.4.1            
 [5] workflowr_1.4.0.9001      baseline_1.2-1           
 [7] gridExtra_2.3             stringr_1.4.0            
 [9] prospectr_0.1.3           RcppArmadillo_0.9.600.4.0
[11] openxlsx_4.1.0.1          magrittr_1.5             
[13] ggplot2_3.2.0             reshape2_1.4.3           
[15] dplyr_0.8.3              

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.2        lattice_0.20-38   tidyr_0.8.3      
 [4] class_7.3-15      assertthat_0.2.1  zeallot_0.1.0    
 [7] rprojroot_1.3-2   digest_0.6.20     foreach_1.4.7    
[10] mime_0.7          R6_2.4.0          plyr_1.8.4       
[13] backports_1.1.4   evaluate_0.14     httr_1.4.1       
[16] highr_0.8         pillar_1.4.2      tfruns_1.4       
[19] rlang_0.4.0       lazyeval_0.2.2    data.table_1.12.2
[22] SparseM_1.77      whisker_0.3-2     Matrix_1.2-17    
[25] reticulate_1.13   rmarkdown_1.14    labeling_0.3     
[28] htmlwidgets_1.3   munsell_0.5.0     shiny_1.3.2      
[31] httpuv_1.5.1      compiler_3.6.1    xfun_0.8         
[34] pkgconfig_2.0.2   base64enc_0.1-3   htmltools_0.3.6  
[37] tidyselect_0.2.5  tibble_2.1.3      codetools_0.2-16 
[40] viridisLite_0.3.0 later_0.8.0       crayon_1.3.4     
[43] withr_2.1.2       grid_3.6.1        xtable_1.8-4     
[46] jsonlite_1.6      gtable_0.3.0      git2r_0.26.1     
[49] scales_1.0.0      zip_2.0.3         stringi_1.4.3    
[52] promises_1.0.1    fs_1.3.1          generics_0.0.2   
[55] iterators_1.0.12  tools_3.6.1       glue_1.3.1       
[58] purrr_0.3.2       crosstalk_1.0.0   yaml_2.2.0       
[61] colorspace_1.4-1  plotly_4.9.0      knitr_1.24       </code></pre>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
